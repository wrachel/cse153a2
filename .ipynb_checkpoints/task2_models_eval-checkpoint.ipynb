{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a6af915-3d41-43ca-a96e-deae9f282a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install pretty_midi\n",
    "# !pip install torch torchvision torchaudio  # Add --index-url https://download.pytorch.org/whl/cu118 for CUDA\n",
    "# !pip install tqdm numpy datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc95750-d5b6-414f-b16b-56df01dc796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pretty_midi\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6d3210e-673c-4d19-a474-15a1ea853b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicTransformerSetup:\n",
    "    \"\"\"Setup and manage the music-transformer repository\"\"\"\n",
    "    \n",
    "    def __init__(self, base_dir=\"./music_transformer_workspace\"):\n",
    "        self.base_dir = base_dir\n",
    "        self.repo_dir = os.path.join(base_dir, \"music-transformer\")\n",
    "        self.models_dir = os.path.join(base_dir, \"pretrained_models\")\n",
    "        self.custom_data_dir = os.path.join(base_dir, \"custom_data\")\n",
    "        self.finetuned_dir = os.path.join(base_dir, \"finetuned_models\")\n",
    "        \n",
    "        # Create directories\n",
    "        # for directory in [self.base_dir, self.models_dir, self.custom_data_dir, self.finetuned_dir]:\n",
    "        #     os.makedirs(directory, exist_ok=True)\n",
    "    \n",
    "    def clone_repository(self):\n",
    "        \"\"\"Clone the music-transformer repository\"\"\"\n",
    "        if os.path.exists(self.repo_dir):\n",
    "            print(\"‚úÖ Repository already exists\")\n",
    "            return True\n",
    "        \n",
    "        try:\n",
    "            print(\"üì• Cloning music-transformer repository...\")\n",
    "            subprocess.run([\n",
    "                \"git\", \"clone\", \n",
    "                \"https://github.com/spectraldoy/music-transformer.git\",\n",
    "                self.repo_dir\n",
    "            ], check=True, cwd=self.base_dir)\n",
    "            \n",
    "            print(\"‚úÖ Repository cloned successfully\")\n",
    "            return True\n",
    "            \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"‚ùå Failed to clone repository: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def install_requirements(self):\n",
    "        \"\"\"Install requirements for music-transformer\"\"\"\n",
    "        requirements_file = os.path.join(self.repo_dir, \"requirements.txt\")\n",
    "        \n",
    "        if not os.path.exists(requirements_file):\n",
    "            print(\"‚ö†Ô∏è  No requirements.txt found, installing basic dependencies...\")\n",
    "            dependencies = [\n",
    "                \"torch>=1.9.0\",\n",
    "                \"numpy>=1.21.0\", \n",
    "                \"pretty_midi>=0.2.9\",\n",
    "                \"tqdm>=4.62.0\",\n",
    "                \"matplotlib>=3.4.0\"\n",
    "            ]\n",
    "            \n",
    "            for dep in dependencies:\n",
    "                try:\n",
    "                    subprocess.run([\"pip\", \"install\", dep], check=True)\n",
    "                    print(f\"‚úÖ Installed {dep}\")\n",
    "                except subprocess.CalledProcessError:\n",
    "                    print(f\"‚ö†Ô∏è  Failed to install {dep}\")\n",
    "        else:\n",
    "            try:\n",
    "                subprocess.run([\"pip\", \"install\", \"-r\", requirements_file], check=True)\n",
    "                print(\"‚úÖ Requirements installed\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"‚ùå Failed to install requirements: {e}\")\n",
    "    \n",
    "    def download_pretrained_models(self):\n",
    "        \"\"\"Check for and download available pretrained models\"\"\"\n",
    "        models_info = {\n",
    "            \"model4v2.pt\": \"https://github.com/spectraldoy/music-transformer/raw/master/models/model4v2.pt\",\n",
    "            \"model6v2.pt\": \"https://github.com/spectraldoy/music-transformer/raw/master/models/model6v2.pt\", \n",
    "            \"chopintransformerv5.pt\": \"https://github.com/spectraldoy/music-transformer/raw/master/models/chopintransformerv5.pt\"\n",
    "        }\n",
    "        \n",
    "        print(\"üîç Checking for pretrained models...\")\n",
    "        \n",
    "        for model_name, model_url in models_info.items():\n",
    "            model_path = os.path.join(self.models_dir, model_name)\n",
    "            \n",
    "            if os.path.exists(model_path):\n",
    "                # Check if it's a real model or placeholder\n",
    "                try:\n",
    "                    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "                    if 'model_state_dict' in checkpoint and len(checkpoint['model_state_dict']) > 0:\n",
    "                        print(f\"‚úÖ {model_name} found (manually uploaded or previously downloaded)\")\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è  {model_name} is a placeholder, attempting download...\")\n",
    "                        self._download_single_model(model_name, model_url, model_path)\n",
    "                except:\n",
    "                    print(f\"‚ö†Ô∏è  {model_name} exists but may be corrupted, attempting download...\")\n",
    "                    self._download_single_model(model_name, model_url, model_path)\n",
    "                continue\n",
    "            \n",
    "            # Model doesn't exist, try to download\n",
    "            self._download_single_model(model_name, model_url, model_path)\n",
    "    \n",
    "    def _download_single_model(self, model_name, model_url, model_path):\n",
    "        \"\"\"Download a single model file\"\"\"\n",
    "        try:\n",
    "            print(f\"üì• Downloading {model_name}...\")\n",
    "            import urllib.request\n",
    "            urllib.request.urlretrieve(model_url, model_path)\n",
    "            print(f\"‚úÖ Downloaded {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to download {model_name}: {e}\")\n",
    "            print(f\"üí° You can manually download from: {model_url}\")\n",
    "            print(f\"   and place it in: {model_path}\")\n",
    "            # Create minimal placeholder that won't interfere with manual uploads\n",
    "            if not os.path.exists(model_path):\n",
    "                torch.save({'model_state_dict': {}, 'config': {}, 'placeholder': True}, model_path)\n",
    "                print(f\"‚ö†Ô∏è  Created placeholder for {model_name}\")\n",
    "    \n",
    "    def list_available_models(self):\n",
    "        \"\"\"List available pretrained models in the models directory\"\"\"\n",
    "        print(f\"üìÇ Available models in {self.models_dir}:\")\n",
    "        \n",
    "        if not os.path.exists(self.models_dir):\n",
    "            print(\"‚ùå Models directory not found\")\n",
    "            return []\n",
    "        \n",
    "        available_models = []\n",
    "        for file in os.listdir(self.models_dir):\n",
    "            if file.endswith('.pt'):\n",
    "                model_path = os.path.join(self.models_dir, file)\n",
    "                try:\n",
    "                    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "                    is_placeholder = checkpoint.get('placeholder', False)\n",
    "                    has_weights = len(checkpoint.get('model_state_dict', {})) > 0\n",
    "                    \n",
    "                    if has_weights and not is_placeholder:\n",
    "                        print(f\"‚úÖ {file} - Ready to use\")\n",
    "                        available_models.append(file)\n",
    "                    else:\n",
    "                        print(f\"‚ö†Ô∏è  {file} - Placeholder (no weights)\")\n",
    "                except:\n",
    "                    print(f\"‚ùå {file} - Corrupted or invalid\")\n",
    "        \n",
    "        if not available_models:\n",
    "            print(\"\\nüí° No valid pretrained models found.\")\n",
    "            print(\"   Please manually download a model and place it in the models directory.\")\n",
    "            print(\"   Available models:\")\n",
    "            print(\"   - model6v2.pt (pure relative attention)\")\n",
    "            print(\"   - model4v2.pt (absolute positional encoding)\")\n",
    "            print(\"   - chopintransformerv5.pt (Chopin specialist)\")\n",
    "        \n",
    "        return available_models\n",
    "    \n",
    "    def setup_workspace(self):\n",
    "        \"\"\"Complete workspace setup\"\"\"\n",
    "        print(\"üöÄ Setting up Music Transformer workspace...\")\n",
    "        \n",
    "        success = self.clone_repository()\n",
    "        if not success:\n",
    "            return False\n",
    "        \n",
    "        self.install_requirements()\n",
    "        self.download_pretrained_models()\n",
    "        \n",
    "        # List available models\n",
    "        available_models = self.list_available_models()\n",
    "        \n",
    "        if available_models:\n",
    "            print(f\"\\nüéØ Workspace ready at: {self.base_dir}\")\n",
    "            print(f\"‚úÖ Found {len(available_models)} usable pretrained model(s)\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è  Workspace setup at: {self.base_dir}\")\n",
    "            print(\"‚ö†Ô∏è  No pretrained models available - you can still train from scratch\")\n",
    "            return True  # Still return True as workspace is functional\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7651f98b-a28d-4ce5-bc12-035ba168fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicTransformerTokenizer:\n",
    "    \"\"\"Tokenizer compatible with spectraldoy/music-transformer\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Build vocabulary based on music-transformer's approach\n",
    "        self.vocab = self._build_vocabulary()\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.token_to_id = {token: i for i, token in enumerate(self.vocab)}\n",
    "        self.id_to_token = {i: token for i, token in enumerate(self.vocab)}\n",
    "        \n",
    "        # Special tokens\n",
    "        self.pad_token = '<pad>'\n",
    "        self.start_token = '<start>'\n",
    "        self.end_token = '<end>'\n",
    "        \n",
    "        print(f\"Music Transformer Tokenizer: {self.vocab_size} tokens\")\n",
    "    \n",
    "    def _build_vocabulary(self):\n",
    "        \"\"\"Build vocabulary matching music-transformer format\"\"\"\n",
    "        vocab = ['<pad>', '<start>', '<end>']\n",
    "        \n",
    "        # Note events: note_on_<pitch>_<velocity>\n",
    "        for pitch in range(21, 109):  # Full piano range\n",
    "            for velocity in range(1, 128, 4):  # Quantized velocities\n",
    "                vocab.append(f'note_on_{pitch}_{velocity}')\n",
    "        \n",
    "        # Note off events\n",
    "        for pitch in range(21, 109):\n",
    "            vocab.append(f'note_off_{pitch}')\n",
    "        \n",
    "        # Time shift events: time_shift_<milliseconds>\n",
    "        for time_shift in range(10, 2000, 10):  # 10ms to 2s\n",
    "            vocab.append(f'time_shift_{time_shift}')\n",
    "        \n",
    "        # Additional tokens for musical structure\n",
    "        vocab.extend(['<bar>', '<phrase_start>', '<phrase_end>'])\n",
    "        \n",
    "        return vocab\n",
    "    \n",
    "    def midi_to_tokens(self, midi_file_path):\n",
    "        \"\"\"Convert MIDI file to token sequence\"\"\"\n",
    "        try:\n",
    "            midi = pretty_midi.PrettyMIDI(midi_file_path)\n",
    "        except:\n",
    "            return []\n",
    "        \n",
    "        tokens = [self.start_token]\n",
    "        \n",
    "        # Extract all note events\n",
    "        all_events = []\n",
    "        for instrument in midi.instruments:\n",
    "            if not instrument.is_drum:\n",
    "                for note in instrument.notes:\n",
    "                    all_events.append(('note_on', note.start, note.pitch, note.velocity))\n",
    "                    all_events.append(('note_off', note.end, note.pitch, 0))\n",
    "        \n",
    "        if not all_events:\n",
    "            return [self.start_token, self.end_token]\n",
    "        \n",
    "        # Sort by time\n",
    "        all_events.sort(key=lambda x: (x[1], x[0] == 'note_off'))\n",
    "        \n",
    "        current_time = 0\n",
    "        for event_type, time, pitch, velocity in all_events:\n",
    "            # Add time shift\n",
    "            time_diff_ms = int((time - current_time) * 1000)\n",
    "            if time_diff_ms > 10:\n",
    "                # Quantize time shift\n",
    "                time_shift = min(time_diff_ms, 1990)\n",
    "                time_shift = (time_shift // 10) * 10\n",
    "                tokens.append(f'time_shift_{time_shift}')\n",
    "                current_time = time\n",
    "            \n",
    "            # Add note event\n",
    "            if event_type == 'note_on' and velocity > 0:\n",
    "                # Quantize velocity\n",
    "                velocity_quantized = (velocity // 4) * 4 + 1\n",
    "                velocity_quantized = max(1, min(velocity_quantized, 125))\n",
    "                tokens.append(f'note_on_{pitch}_{velocity_quantized}')\n",
    "            elif event_type == 'note_off':\n",
    "                tokens.append(f'note_off_{pitch}')\n",
    "        \n",
    "        tokens.append(self.end_token)\n",
    "        \n",
    "        # Limit sequence length\n",
    "        if len(tokens) > 2048:\n",
    "            tokens = tokens[:2048]\n",
    "            tokens[-1] = self.end_token\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    def encode(self, tokens):\n",
    "        \"\"\"Convert tokens to IDs\"\"\"\n",
    "        return [self.token_to_id.get(token, 0) for token in tokens]\n",
    "    \n",
    "    def decode(self, token_ids):\n",
    "        \"\"\"Convert IDs back to tokens\"\"\"\n",
    "        return [self.id_to_token.get(id, self.pad_token) for id in token_ids]\n",
    "    \n",
    "    def tokens_to_midi(self, tokens, output_file):\n",
    "        \"\"\"Convert tokens back to MIDI\"\"\"\n",
    "        midi = pretty_midi.PrettyMIDI()\n",
    "        instrument = pretty_midi.Instrument(program=0)\n",
    "        \n",
    "        current_time = 0\n",
    "        active_notes = {}\n",
    "        \n",
    "        for token in tokens:\n",
    "            if token.startswith('time_shift_'):\n",
    "                time_ms = int(token.split('_')[-1])\n",
    "                current_time += time_ms / 1000.0\n",
    "            \n",
    "            elif token.startswith('note_on_'):\n",
    "                parts = token.split('_')\n",
    "                pitch = int(parts[2])\n",
    "                velocity = int(parts[3])\n",
    "                active_notes[pitch] = (current_time, velocity)\n",
    "            \n",
    "            elif token.startswith('note_off_'):\n",
    "                pitch = int(token.split('_')[-1])\n",
    "                if pitch in active_notes:\n",
    "                    start_time, velocity = active_notes[pitch]\n",
    "                    note = pretty_midi.Note(\n",
    "                        velocity=velocity,\n",
    "                        pitch=pitch,\n",
    "                        start=start_time,\n",
    "                        end=current_time\n",
    "                    )\n",
    "                    instrument.notes.append(note)\n",
    "                    del active_notes[pitch]\n",
    "        \n",
    "        midi.instruments.append(instrument)\n",
    "        midi.write(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7855f6dc-da2e-4c17-9d3d-183d90233ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicTransformerModel(nn.Module):\n",
    "    \"\"\"Music Transformer model architecture\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, d_model=512, nhead=8, num_layers=6, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Embeddings\n",
    "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.position_embedding = nn.Embedding(4096, d_model)  # Max sequence length\n",
    "        \n",
    "        # Transformer layers with relative position encoding\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_projection = nn.Linear(d_model, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        \"\"\"Initialize weights\"\"\"\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        seq_len = input_ids.size(1)\n",
    "        \n",
    "        # Create position IDs\n",
    "        position_ids = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n",
    "        \n",
    "        # Embeddings\n",
    "        token_embeds = self.token_embedding(input_ids)\n",
    "        pos_embeds = self.position_embedding(position_ids)\n",
    "        \n",
    "        x = self.dropout(token_embeds + pos_embeds)\n",
    "        \n",
    "        # Causal mask\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
    "        mask = mask.to(input_ids.device)\n",
    "        \n",
    "        # Apply transformer\n",
    "        x = self.transformer(x, mask=mask)\n",
    "        \n",
    "        # Output projection\n",
    "        logits = self.output_projection(x)\n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c98f7d2-c8b9-48e4-a6c1-e3da9b3cc470",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMidiDataset(Dataset):\n",
    "    \"\"\"Dataset for custom MIDI files\"\"\"\n",
    "    \n",
    "    def __init__(self, midi_dir, tokenizer, max_length=1024):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.sequences = self._load_midi_files(midi_dir)\n",
    "    \n",
    "    def _load_midi_files(self, midi_dir):\n",
    "        \"\"\"Load and process MIDI files\"\"\"\n",
    "        sequences = []\n",
    "        midi_files = [f for f in os.listdir(midi_dir) if f.endswith(('.mid', '.midi'))]\n",
    "        \n",
    "        print(f\"Processing {len(midi_files)} MIDI files...\")\n",
    "        \n",
    "        for midi_file in tqdm(midi_files):\n",
    "            file_path = os.path.join(midi_dir, midi_file)\n",
    "            tokens = self.tokenizer.midi_to_tokens(file_path)\n",
    "            \n",
    "            if len(tokens) > 10:  # Filter out empty/very short sequences\n",
    "                token_ids = self.tokenizer.encode(tokens)\n",
    "                \n",
    "                # Create overlapping chunks\n",
    "                stride = self.max_length // 2\n",
    "                for i in range(0, len(token_ids), stride):\n",
    "                    chunk = token_ids[i:i + self.max_length]\n",
    "                    if len(chunk) >= 20:  # Minimum chunk size\n",
    "                        sequences.append(chunk)\n",
    "        \n",
    "        print(f\"Created {len(sequences)} training sequences from {len(midi_files)} files\")\n",
    "        return sequences\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        \n",
    "        # Pad sequence\n",
    "        if len(sequence) < self.max_length:\n",
    "            sequence = sequence + [0] * (self.max_length - len(sequence))  # Pad with <pad> token\n",
    "        \n",
    "        # Convert to tensors\n",
    "        input_ids = torch.tensor(sequence[:-1], dtype=torch.long)  # Input\n",
    "        labels = torch.tensor(sequence[1:], dtype=torch.long)      # Target (shifted by 1)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ef79751-6a9b-4f24-a354-22e28149152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMusicTransformerFinetuner:\n",
    "    \"\"\"Simplified finetuner - assumes model6v2.pt is already uploaded\"\"\"\n",
    "    \n",
    "    def __init__(self, workspace_dir, train_dir, test_dir, pretrained_model=\"model6v2.pt\"):\n",
    "        self.workspace_dir = workspace_dir\n",
    "        self.train_dir = train_dir\n",
    "        self.test_dir = test_dir\n",
    "        self.pretrained_model = pretrained_model\n",
    "        \n",
    "        # Create necessary directories\n",
    "        self.models_dir = os.path.join(workspace_dir, \"pretrained_models\")\n",
    "        self.finetuned_dir = os.path.join(workspace_dir, \"finetuned_models\")\n",
    "        os.makedirs(self.finetuned_dir, exist_ok=True)\n",
    "        \n",
    "        # Setup\n",
    "        self.tokenizer = MusicTransformerTokenizer()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        print(f\"Using device: {self.device}\")\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        \"\"\"Prepare training and validation datasets\"\"\"\n",
    "        print(\"üìä Preparing datasets...\")\n",
    "        \n",
    "        self.train_dataset = CustomMidiDataset(self.train_dir, self.tokenizer)\n",
    "        self.val_dataset = CustomMidiDataset(self.test_dir, self.tokenizer)\n",
    "        \n",
    "        print(f\"Training samples: {len(self.train_dataset)}\")\n",
    "        print(f\"Validation samples: {len(self.val_dataset)}\")\n",
    "        \n",
    "        if len(self.train_dataset) == 0:\n",
    "            raise ValueError(\"No training data found! Check your MIDI directory.\")\n",
    "    \n",
    "    def load_pretrained_model(self):\n",
    "        \"\"\"Load pretrained Music Transformer model (simplified)\"\"\"\n",
    "        pretrained_path = os.path.join(self.models_dir, self.pretrained_model)\n",
    "        \n",
    "        if not os.path.exists(pretrained_path):\n",
    "            print(f\"‚ùå Pretrained model not found: {pretrained_path}\")\n",
    "            print(\"üîÑ Creating new model from scratch...\")\n",
    "            model = MusicTransformerModel(vocab_size=self.tokenizer.vocab_size)\n",
    "            return model.to(self.device)\n",
    "        \n",
    "        try:\n",
    "            print(f\"üì• Loading pretrained model: {self.pretrained_model}\")\n",
    "            checkpoint = torch.load(pretrained_path, map_location=self.device)\n",
    "            \n",
    "            # Check if it's a placeholder\n",
    "            if checkpoint.get('placeholder', False):\n",
    "                print(\"‚ö†Ô∏è  Model is a placeholder, creating new model from scratch...\")\n",
    "                model = MusicTransformerModel(vocab_size=self.tokenizer.vocab_size)\n",
    "                return model.to(self.device)\n",
    "            \n",
    "            # Create model\n",
    "            model = MusicTransformerModel(vocab_size=self.tokenizer.vocab_size)\n",
    "            \n",
    "            # Get state dict\n",
    "            if 'model_state_dict' in checkpoint:\n",
    "                state_dict = checkpoint['model_state_dict']\n",
    "            else:\n",
    "                state_dict = checkpoint\n",
    "            \n",
    "            if not state_dict:\n",
    "                print(\"‚ö†Ô∏è  Model has no weights, creating new model from scratch...\")\n",
    "                model = MusicTransformerModel(vocab_size=self.tokenizer.vocab_size)\n",
    "                return model.to(self.device)\n",
    "            \n",
    "            # Handle vocabulary size differences\n",
    "            if 'token_embedding.weight' in state_dict:\n",
    "                pretrained_embed_shape = state_dict['token_embedding.weight'].shape\n",
    "                current_embed_shape = model.token_embedding.weight.shape\n",
    "                \n",
    "                if pretrained_embed_shape != current_embed_shape:\n",
    "                    print(f\"üîß Adjusting vocabulary size:\")\n",
    "                    print(f\"   Pretrained: {pretrained_embed_shape[0]} ‚Üí Current: {current_embed_shape[0]}\")\n",
    "                    \n",
    "                    old_vocab_size = pretrained_embed_shape[0]\n",
    "                    new_vocab_size = current_embed_shape[0]\n",
    "                    \n",
    "                    # Adjust token embeddings\n",
    "                    if new_vocab_size > old_vocab_size:\n",
    "                        # Add new random embeddings\n",
    "                        new_embeddings = torch.randn(new_vocab_size - old_vocab_size, model.d_model) * 0.02\n",
    "                        state_dict['token_embedding.weight'] = torch.cat([\n",
    "                            state_dict['token_embedding.weight'], \n",
    "                            new_embeddings\n",
    "                        ], dim=0)\n",
    "                    else:\n",
    "                        # Truncate embeddings\n",
    "                        state_dict['token_embedding.weight'] = state_dict['token_embedding.weight'][:new_vocab_size]\n",
    "                    \n",
    "                    # Adjust output projection\n",
    "                    if 'output_projection.weight' in state_dict:\n",
    "                        if new_vocab_size > old_vocab_size:\n",
    "                            new_output_weights = torch.randn(new_vocab_size - old_vocab_size, model.d_model) * 0.02\n",
    "                            state_dict['output_projection.weight'] = torch.cat([\n",
    "                                state_dict['output_projection.weight'],\n",
    "                                new_output_weights\n",
    "                            ], dim=0)\n",
    "                            \n",
    "                            if 'output_projection.bias' in state_dict:\n",
    "                                new_output_bias = torch.zeros(new_vocab_size - old_vocab_size)\n",
    "                                state_dict['output_projection.bias'] = torch.cat([\n",
    "                                    state_dict['output_projection.bias'],\n",
    "                                    new_output_bias\n",
    "                                ], dim=0)\n",
    "                        else:\n",
    "                            state_dict['output_projection.weight'] = state_dict['output_projection.weight'][:new_vocab_size]\n",
    "                            if 'output_projection.bias' in state_dict:\n",
    "                                state_dict['output_projection.bias'] = state_dict['output_projection.bias'][:new_vocab_size]\n",
    "            \n",
    "            # Load the adjusted weights\n",
    "            missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)\n",
    "            \n",
    "            if missing_keys:\n",
    "                print(f\"‚ö†Ô∏è  Missing keys (randomly initialized): {len(missing_keys)}\")\n",
    "            if unexpected_keys:\n",
    "                print(f\"‚ö†Ô∏è  Unexpected keys (ignored): {len(unexpected_keys)}\")\n",
    "            \n",
    "            print(\"‚úÖ Pretrained model loaded successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load pretrained model: {e}\")\n",
    "            print(\"üîÑ Creating new model from scratch...\")\n",
    "            model = MusicTransformerModel(vocab_size=self.tokenizer.vocab_size)\n",
    "        \n",
    "        return model.to(self.device)\n",
    "    \n",
    "    def finetune(self, epochs=20, batch_size=4, learning_rate=5e-5, save_steps=500):\n",
    "        \"\"\"Finetune the model (same as before)\"\"\"\n",
    "        print(\"üéØ Starting finetuning...\")\n",
    "        \n",
    "        # Prepare data\n",
    "        self.prepare_data()\n",
    "        \n",
    "        # Load model\n",
    "        model = self.load_pretrained_model()\n",
    "        \n",
    "        print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "        \n",
    "        # Data loaders\n",
    "        train_loader = DataLoader(\n",
    "            self.train_dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=True,\n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        val_loader = DataLoader(\n",
    "            self.val_dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=False,\n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        # Optimizer and loss\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "        \n",
    "        # Training loop\n",
    "        best_val_loss = float('inf')\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            epoch_train_loss = 0\n",
    "            \n",
    "            for batch_idx, batch in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\")):\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                labels = batch['labels'].to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                logits = model(input_ids)\n",
    "                loss = criterion(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_train_loss += loss.item()\n",
    "                \n",
    "                if (batch_idx + 1) % save_steps == 0:\n",
    "                    checkpoint_path = os.path.join(\n",
    "                        self.finetuned_dir, \n",
    "                        f\"checkpoint_epoch_{epoch+1}_step_{batch_idx+1}.pt\"\n",
    "                    )\n",
    "                    torch.save({\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'epoch': epoch,\n",
    "                        'batch_idx': batch_idx,\n",
    "                        'loss': loss.item()\n",
    "                    }, checkpoint_path)\n",
    "            \n",
    "            avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "            train_losses.append(avg_train_loss)\n",
    "            \n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            epoch_val_loss = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\"):\n",
    "                    input_ids = batch['input_ids'].to(self.device)\n",
    "                    labels = batch['labels'].to(self.device)\n",
    "                    \n",
    "                    logits = model(input_ids)\n",
    "                    loss = criterion(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "                    epoch_val_loss += loss.item()\n",
    "            \n",
    "            avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "            val_losses.append(avg_val_loss)\n",
    "            scheduler.step()\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "            print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "            print(f\"  Val Loss: {avg_val_loss:.4f}\")\n",
    "            print(f\"  Learning Rate: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_model_path = os.path.join(self.finetuned_dir, \"best_model.pt\")\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'tokenizer': self.tokenizer,\n",
    "                    'config': {\n",
    "                        'vocab_size': self.tokenizer.vocab_size,\n",
    "                        'best_val_loss': best_val_loss,\n",
    "                        'epoch': epoch + 1\n",
    "                    }\n",
    "                }, best_model_path)\n",
    "                print(f\"‚úÖ Saved best model (val_loss: {best_val_loss:.4f})\")\n",
    "        \n",
    "        # Save final model\n",
    "        final_model_path = os.path.join(self.finetuned_dir, \"final_model.pt\")\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'tokenizer': self.tokenizer,\n",
    "            'training_history': {\n",
    "                'train_losses': train_losses,\n",
    "                'val_losses': val_losses,\n",
    "                'best_val_loss': best_val_loss\n",
    "            }\n",
    "        }, final_model_path)\n",
    "        \n",
    "        print(f\"üéâ Finetuning complete!\")\n",
    "        print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "        print(f\"Models saved to: {self.finetuned_dir}\")\n",
    "        \n",
    "        return final_model_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01a8b6ff-de8c-481e-a792-d238cbcdb9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicTransformerGenerator:\n",
    "    \"\"\"Generate music with finetuned Music Transformer\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Load model and tokenizer\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        self.tokenizer = checkpoint['tokenizer']\n",
    "        \n",
    "        # Create and load model\n",
    "        self.model = MusicTransformerModel(vocab_size=self.tokenizer.vocab_size)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        print(f\"‚úÖ Generator loaded from {model_path}\")\n",
    "    \n",
    "    def generate(self, prompt=None, max_length=2048, temperature=0.8, top_k=40, top_p=0.9):\n",
    "        \"\"\"Generate music tokens\"\"\"\n",
    "        \n",
    "        if prompt is None:\n",
    "            prompt_tokens = [self.tokenizer.start_token]\n",
    "        else:\n",
    "            prompt_tokens = prompt if isinstance(prompt, list) else [prompt]\n",
    "        \n",
    "        # Encode prompt\n",
    "        token_ids = self.tokenizer.encode(prompt_tokens)\n",
    "        input_ids = torch.tensor([token_ids], device=self.device)\n",
    "        \n",
    "        print(f\"üéµ Generating music (prompt: {len(prompt_tokens)} tokens)...\")\n",
    "        \n",
    "        generated_tokens = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(max_length):\n",
    "                # Forward pass\n",
    "                logits = self.model(input_ids)\n",
    "                next_token_logits = logits[0, -1, :] / temperature\n",
    "                \n",
    "                # Apply top-k and top-p filtering\n",
    "                if top_k > 0:\n",
    "                    top_k_logits, top_k_indices = torch.topk(next_token_logits, top_k)\n",
    "                    next_token_logits = torch.full_like(next_token_logits, float('-inf'))\n",
    "                    next_token_logits[top_k_indices] = top_k_logits\n",
    "                \n",
    "                if top_p < 1.0:\n",
    "                    sorted_logits, sorted_indices = torch.sort(next_token_logits, descending=True)\n",
    "                    cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "                    sorted_indices_to_remove = cumulative_probs > top_p\n",
    "                    sorted_indices_to_remove[1:] = sorted_indices_to_remove[:-1].clone()\n",
    "                    sorted_indices_to_remove[0] = 0\n",
    "                    next_token_logits[sorted_indices[sorted_indices_to_remove]] = float('-inf')\n",
    "                \n",
    "                # Sample next token\n",
    "                probs = torch.softmax(next_token_logits, dim=-1)\n",
    "                next_token = torch.multinomial(probs, 1)\n",
    "                \n",
    "                # Check for end token\n",
    "                next_token_str = self.tokenizer.id_to_token[next_token.item()]\n",
    "                if next_token_str == self.tokenizer.end_token:\n",
    "                    break\n",
    "                \n",
    "                generated_tokens.append(next_token_str)\n",
    "                \n",
    "                # Update input\n",
    "                input_ids = torch.cat([input_ids, next_token.unsqueeze(0)], dim=1)\n",
    "                \n",
    "                # Limit sequence length to prevent memory issues\n",
    "                if input_ids.size(1) > 2048:\n",
    "                    input_ids = input_ids[:, -1024:]  # Keep last 1024 tokens\n",
    "        \n",
    "        print(f\"Generated {len(generated_tokens)} tokens\")\n",
    "        return generated_tokens\n",
    "    \n",
    "    def generate_midi(self, output_file, prompt=None, max_length=2048, temperature=0.8, top_k=40, top_p=0.9):\n",
    "        \"\"\"Generate and save MIDI file\"\"\"\n",
    "        \n",
    "        # Generate tokens\n",
    "        tokens = self.generate(prompt, max_length, temperature, top_k, top_p)\n",
    "        \n",
    "        # Convert to MIDI\n",
    "        if prompt:\n",
    "            full_tokens = (prompt if isinstance(prompt, list) else [prompt]) + tokens\n",
    "        else:\n",
    "            full_tokens = [self.tokenizer.start_token] + tokens\n",
    "        \n",
    "        self.tokenizer.tokens_to_midi(full_tokens, output_file)\n",
    "        print(f\"üéº MIDI saved to: {output_file}\")\n",
    "        \n",
    "        return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1047ad0-919d-47bc-a93e-236f62c09e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_music_transformer_workspace(workspace_dir=\"./music_transformer_workspace\"):\n",
    "    \"\"\"Setup the complete workspace\"\"\"\n",
    "    setup = MusicTransformerSetup(workspace_dir)\n",
    "    success = setup.setup_workspace()\n",
    "    \n",
    "    if success:\n",
    "        print(f\"üéØ Workspace ready at: {workspace_dir}\")\n",
    "        return workspace_dir\n",
    "    else:\n",
    "        print(\"‚ùå Workspace setup failed\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29a0ee95-0d0b-424b-8932-06efa97a0ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_music_transformer_workspace(workspace_dir=\"./music_transformer_workspace\"):\n",
    "    \"\"\"Simple workspace setup - assumes model6v2.pt is already uploaded\"\"\"\n",
    "    \n",
    "    print(\"üöÄ Setting up simple Music Transformer workspace...\")\n",
    "    \n",
    "    # Create necessary directories\n",
    "    directories = {\n",
    "        'base': workspace_dir,\n",
    "        'models': os.path.join(workspace_dir, \"pretrained_models\"),\n",
    "        'custom_data': os.path.join(workspace_dir, \"custom_data\"), \n",
    "        'finetuned': os.path.join(workspace_dir, \"finetuned_models\"),\n",
    "        'generated': os.path.join(workspace_dir, \"generated_music\")\n",
    "    }\n",
    "    \n",
    "    for name, directory in directories.items():\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        print(f\"‚úÖ Created {name} directory: {directory}\")\n",
    "    \n",
    "    # Check for uploaded model\n",
    "    model_path = os.path.join(directories['models'], \"model6v2.pt\")\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        try:\n",
    "            # Test if it's a real model file\n",
    "            checkpoint = torch.load(model_path, map_location='cpu')\n",
    "            if checkpoint.get('placeholder', False) or not checkpoint.get('model_state_dict', {}):\n",
    "                print(f\"‚ö†Ô∏è  Found model6v2.pt but it appears to be empty/placeholder\")\n",
    "                print(f\"üí°  Please upload a real model6v2.pt to: {model_path}\")\n",
    "            else:\n",
    "                print(f\"‚úÖ Found valid model6v2.pt\")\n",
    "                \n",
    "                # Show model info\n",
    "                state_dict = checkpoint.get('model_state_dict', checkpoint)\n",
    "                print(f\"üìä Model contains {len(state_dict)} parameter groups\")\n",
    "                \n",
    "                if 'token_embedding.weight' in state_dict:\n",
    "                    vocab_size, embed_dim = state_dict['token_embedding.weight'].shape\n",
    "                    print(f\"üìù Pretrained vocabulary size: {vocab_size}\")\n",
    "                    print(f\"üß† Embedding dimension: {embed_dim}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error reading model6v2.pt: {e}\")\n",
    "            print(f\"üí°  Please upload a valid model6v2.pt to: {model_path}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  model6v2.pt not found at: {model_path}\")\n",
    "        print(f\"üí°  Please upload model6v2.pt to that location\")\n",
    "    \n",
    "    # Install basic dependencies (if needed)\n",
    "    try:\n",
    "        import pretty_midi\n",
    "        import tqdm\n",
    "        print(\"‚úÖ Required packages already installed\")\n",
    "    except ImportError:\n",
    "        print(\"üì¶ Installing basic requirements...\")\n",
    "        import subprocess\n",
    "        packages = [\"pretty_midi\", \"tqdm\", \"numpy\"]\n",
    "        for package in packages:\n",
    "            try:\n",
    "                subprocess.run([\"pip\", \"install\", package], check=True, capture_output=True)\n",
    "                print(f\"‚úÖ Installed {package}\")\n",
    "            except:\n",
    "                print(f\"‚ö†Ô∏è  Could not install {package}\")\n",
    "    \n",
    "    print(f\"\\nüéØ Simple workspace ready at: {workspace_dir}\")\n",
    "    print(\"üìÅ Directory structure:\")\n",
    "    for name, directory in directories.items():\n",
    "        print(f\"   {name}: {directory}\")\n",
    "    \n",
    "    return workspace_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "689636e4-fe2e-4bc9-90fd-8760e55243e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_music_transformer(workspace_dir, train_dir, test_dir, \n",
    "                              pretrained_model=\"model6v2.pt\", \n",
    "                              epochs=5, batch_size=4):\n",
    "    \"\"\"Simplified finetune Music Transformer on custom data\"\"\"\n",
    "    \n",
    "    print(\"üéµ Starting simplified Music Transformer finetuning...\")\n",
    "    \n",
    "    finetuner = SimpleMusicTransformerFinetuner(\n",
    "        workspace_dir=workspace_dir,\n",
    "        train_dir=train_dir,\n",
    "        test_dir=test_dir,\n",
    "        pretrained_model=pretrained_model\n",
    "    )\n",
    "    \n",
    "    model_path = finetuner.finetune(\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=5e-5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06a00fc2-3aad-423c-92fc-1f79753e5202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_music_with_finetuned_model(model_path, output_file, \n",
    "                                       temperature=0.8, max_length=2048):\n",
    "    \"\"\"Generate music with finetuned model\"\"\"\n",
    "    \n",
    "    generator = MusicTransformerGenerator(model_path)\n",
    "    tokens = generator.generate_midi(\n",
    "        output_file=output_file,\n",
    "        temperature=temperature,\n",
    "        max_length=max_length\n",
    "    )\n",
    "    \n",
    "    return generator, tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15d7bf88-3a5a-4132-ab08-d252b37adeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_finetuning_workflow(train_dir, test_dir, workspace_dir=\"./music_transformer_workspace\"):\n",
    "    \"\"\"Complete workflow: setup ‚Üí finetune ‚Üí generate\"\"\"\n",
    "    \n",
    "    print(\"üöÄ Starting complete Music Transformer finetuning workflow\")\n",
    "    \n",
    "    # Step 1: Setup workspace\n",
    "    workspace = setup_music_transformer_workspace(workspace_dir)\n",
    "    if not workspace:\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Finetune model\n",
    "    model_path = finetune_music_transformer(\n",
    "        workspace_dir=workspace,\n",
    "        train_dir=train_dir,\n",
    "        test_dir=test_dir,\n",
    "        epochs=5,\n",
    "        batch_size=4\n",
    "    )\n",
    "    \n",
    "    # Step 3: Generate samples\n",
    "    generator, tokens = generate_music_with_finetuned_model(\n",
    "        model_path=model_path,\n",
    "        output_file=os.path.join(workspace, \"generated_sample.mid\"),\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Complete workflow finished!\")\n",
    "    print(f\"üìÅ Check {workspace} for results\")\n",
    "    \n",
    "    return {\n",
    "        'workspace': workspace,\n",
    "        'model_path': model_path,\n",
    "        'generator': generator\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f7b5579-15ae-4d4f-8078-1960c8797864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_manually_uploaded_model(workspace_dir=\"./music_transformer_workspace\", model_name=\"model6v2.pt\"):\n",
    "    \"\"\"Test if manually uploaded model is working correctly\"\"\"\n",
    "    \n",
    "    print(f\"üß™ Testing manually uploaded model: {model_name}\")\n",
    "    \n",
    "    setup = MusicTransformerSetup(workspace_dir)\n",
    "    model_path = os.path.join(setup.models_dir, model_name)\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Model not found: {model_path}\")\n",
    "        print(f\"üí° Please upload {model_name} to: {setup.models_dir}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Try to load the model\n",
    "        checkpoint = torch.load(model_path, map_location='cpu')\n",
    "        \n",
    "        # Check if it's a placeholder\n",
    "        if checkpoint.get('placeholder', False):\n",
    "            print(f\"‚ùå {model_name} is a placeholder, not a real model\")\n",
    "            return False\n",
    "        \n",
    "        # Check if it has weights\n",
    "        state_dict = checkpoint.get('model_state_dict', checkpoint)\n",
    "        if not state_dict or len(state_dict) == 0:\n",
    "            print(f\"‚ùå {model_name} has no model weights\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"‚úÖ {model_name} loaded successfully\")\n",
    "        print(f\"üìä Model contains {len(state_dict)} parameter groups\")\n",
    "        \n",
    "        # Show some key info\n",
    "        if 'token_embedding.weight' in state_dict:\n",
    "            vocab_size, embed_dim = state_dict['token_embedding.weight'].shape\n",
    "            print(f\"üìù Vocabulary size: {vocab_size}\")\n",
    "            print(f\"üß† Embedding dimension: {embed_dim}\")\n",
    "        \n",
    "        # Test creating a model with this checkpoint\n",
    "        tokenizer = MusicTransformerTokenizer()\n",
    "        model = MusicTransformerModel(vocab_size=tokenizer.vocab_size)\n",
    "        \n",
    "        # Try loading (with potential vocab size adjustment)\n",
    "        if 'token_embedding.weight' in state_dict:\n",
    "            pretrained_vocab = state_dict['token_embedding.weight'].shape[0]\n",
    "            current_vocab = tokenizer.vocab_size\n",
    "            \n",
    "            if pretrained_vocab != current_vocab:\n",
    "                print(f\"‚ö†Ô∏è  Vocab size mismatch: pretrained={pretrained_vocab}, current={current_vocab}\")\n",
    "                print(\"üîß This will be automatically adjusted during finetuning\")\n",
    "        \n",
    "        print(f\"‚úÖ {model_name} is ready for finetuning!\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error testing {model_name}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bc66fd1-def6-459d-af84-8969ea686c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_music_transformer_test(train_dir, test_dir):\n",
    "    \"\"\"Quick test of the entire pipeline\"\"\"\n",
    "    \n",
    "    print(\"üß™ Quick Music Transformer test\")\n",
    "    \n",
    "    # Check if directories exist and have MIDI files\n",
    "    if not os.path.exists(train_dir):\n",
    "        print(f\"‚ùå Training directory not found: {train_dir}\")\n",
    "        return None\n",
    "    \n",
    "    train_files = [f for f in os.listdir(train_dir) if f.endswith(('.mid', '.midi'))]\n",
    "    if len(train_files) == 0:\n",
    "        print(f\"‚ùå No MIDI files found in {train_dir}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(train_files)} training files\")\n",
    "    \n",
    "    # Test manually uploaded models first\n",
    "    workspace_dir = \"./music_transformer_workspace\"\n",
    "    setup = MusicTransformerSetup(workspace_dir)\n",
    "    setup.setup_workspace()\n",
    "    \n",
    "    # Test the manually uploaded model\n",
    "    test_manually_uploaded_model(workspace_dir, \"model6v2.pt\")\n",
    "    \n",
    "    # Run complete workflow\n",
    "    results = complete_finetuning_workflow(train_dir, test_dir)\n",
    "    \n",
    "    if results:\n",
    "        # Generate additional samples with different parameters\n",
    "        generator = results['generator']\n",
    "        workspace = results['workspace']\n",
    "        \n",
    "        print(\"üéº Generating additional samples...\")\n",
    "        \n",
    "        samples = [\n",
    "            (\"conservative.mid\", 0.6),\n",
    "            (\"balanced.mid\", 0.8), \n",
    "            (\"creative.mid\", 1.0),\n",
    "            (\"very_creative.mid\", 1.2)\n",
    "        ]\n",
    "        \n",
    "        for filename, temp in samples:\n",
    "            output_path = os.path.join(workspace, filename)\n",
    "            try:\n",
    "                generator.generate_midi(output_path, temperature=temp, max_length=256)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Failed to generate {filename}: {e}\")\n",
    "        \n",
    "        print(\"üéâ Test complete! Check the workspace for generated music.\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "169e3fc8-5581-4a20-98d3-414f48191037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_uploaded_model(workspace_dir=\"./music_transformer_workspace\", model_name=\"model6v2.pt\"):\n",
    "    \"\"\"Quick check if your uploaded model is ready to use\"\"\"\n",
    "    \n",
    "    print(f\"üîç Checking uploaded model: {model_name}\")\n",
    "    \n",
    "    models_dir = os.path.join(workspace_dir, \"pretrained_models\")\n",
    "    model_path = os.path.join(models_dir, model_name)\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"‚ùå Model not found: {model_path}\")\n",
    "        print(f\"üí° Please upload {model_name} to: {models_dir}\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load(model_path, map_location='cpu')\n",
    "        \n",
    "        if checkpoint.get('placeholder', False):\n",
    "            print(f\"‚ùå {model_name} is a placeholder, not a real model\")\n",
    "            return False\n",
    "        \n",
    "        state_dict = checkpoint.get('model_state_dict', checkpoint)\n",
    "        if not state_dict or len(state_dict) == 0:\n",
    "            print(f\"‚ùå {model_name} has no model weights\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"‚úÖ {model_name} is valid and ready to use!\")\n",
    "        \n",
    "        if 'token_embedding.weight' in state_dict:\n",
    "            vocab_size, embed_dim = state_dict['token_embedding.weight'].shape\n",
    "            print(f\"üìù Pretrained vocabulary: {vocab_size} tokens\")\n",
    "            print(f\"üß† Embedding dimension: {embed_dim}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error reading {model_name}: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e363a0d8-6d6e-40d5-bc8e-67a44d857c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_complete_workflow(train_dir, test_dir, workspace_dir=\"./music_transformer_workspace\"):\n",
    "    \"\"\"Simplified complete workflow - assumes model6v2.pt is uploaded\"\"\"\n",
    "    \n",
    "    print(\"üöÄ Starting simplified Music Transformer workflow\")\n",
    "    \n",
    "    # Step 1: Simple setup (no cloning/downloading)\n",
    "    workspace = setup_music_transformer_workspace(workspace_dir)\n",
    "    \n",
    "    # Step 1.5: Check if model is properly uploaded\n",
    "    if not check_uploaded_model(workspace_dir, \"model6v2.pt\"):\n",
    "        print(\"‚ùå Please upload model6v2.pt before continuing\")\n",
    "        return None\n",
    "    \n",
    "    # Step 2: Finetune with uploaded model\n",
    "    model_path = finetune_music_transformer(\n",
    "        workspace_dir=workspace,\n",
    "        train_dir=train_dir,\n",
    "        test_dir=test_dir,\n",
    "        pretrained_model=\"model6v2.pt\",  # Your uploaded model\n",
    "        epochs=100,\n",
    "        batch_size=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0aaae1-3ceb-4efe-9676-0d2594fd2c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_uploaded_model(\"./music_transformer_workspace/finetuned_models\", \"final_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc0fddb1-09c9-42ee-bee7-b40c82743517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting simplified Music Transformer workflow\n",
      "üöÄ Setting up simple Music Transformer workspace...\n",
      "‚úÖ Created base directory: ./music_transformer_workspace\n",
      "‚úÖ Created models directory: ./music_transformer_workspace/pretrained_models\n",
      "‚úÖ Created custom_data directory: ./music_transformer_workspace/custom_data\n",
      "‚úÖ Created finetuned directory: ./music_transformer_workspace/finetuned_models\n",
      "‚úÖ Created generated directory: ./music_transformer_workspace/generated_music\n",
      "‚ö†Ô∏è  Found model6v2.pt but it appears to be empty/placeholder\n",
      "üí°  Please upload a real model6v2.pt to: ./music_transformer_workspace/pretrained_models/model6v2.pt\n",
      "‚úÖ Required packages already installed\n",
      "\n",
      "üéØ Simple workspace ready at: ./music_transformer_workspace\n",
      "üìÅ Directory structure:\n",
      "   base: ./music_transformer_workspace\n",
      "   models: ./music_transformer_workspace/pretrained_models\n",
      "   custom_data: ./music_transformer_workspace/custom_data\n",
      "   finetuned: ./music_transformer_workspace/finetuned_models\n",
      "   generated: ./music_transformer_workspace/generated_music\n",
      "üîç Checking uploaded model: model6v2.pt\n",
      "‚úÖ model6v2.pt is valid and ready to use!\n",
      "üéµ Starting simplified Music Transformer finetuning...\n",
      "Music Transformer Tokenizer: 3109 tokens\n",
      "Using device: cuda\n",
      "üéØ Starting finetuning...\n",
      "üìä Preparing datasets...\n",
      "Processing 229 MIDI files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 229/229 [00:01<00:00, 221.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 313 training sequences from 229 files\n",
      "Processing 77 MIDI files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77/77 [00:00<00:00, 213.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 111 training sequences from 77 files\n",
      "Training samples: 313\n",
      "Validation samples: 111\n",
      "üì• Loading pretrained model: model6v2.pt\n",
      "‚ö†Ô∏è  Missing keys (randomly initialized): 76\n",
      "‚ö†Ô∏è  Unexpected keys (ignored): 2\n",
      "‚úÖ Pretrained model loaded successfully\n",
      "Model parameters: 24,198,181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:23<00:00,  3.35it/s]\n",
      "Epoch 1 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Train Loss: 5.4159\n",
      "  Val Loss: 4.0626\n",
      "  Learning Rate: 4.88e-05\n",
      "‚úÖ Saved best model (val_loss: 4.0626)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:23<00:00,  3.34it/s]\n",
      "Epoch 2 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:\n",
      "  Train Loss: 3.6252\n",
      "  Val Loss: 3.3359\n",
      "  Learning Rate: 4.52e-05\n",
      "‚úÖ Saved best model (val_loss: 3.3359)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:23<00:00,  3.35it/s]\n",
      "Epoch 3 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:\n",
      "  Train Loss: 3.1927\n",
      "  Val Loss: 3.1283\n",
      "  Learning Rate: 3.97e-05\n",
      "‚úÖ Saved best model (val_loss: 3.1283)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:23<00:00,  3.35it/s]\n",
      "Epoch 4 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:\n",
      "  Train Loss: 3.0451\n",
      "  Val Loss: 3.0362\n",
      "  Learning Rate: 3.27e-05\n",
      "‚úÖ Saved best model (val_loss: 3.0362)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:23<00:00,  3.34it/s]\n",
      "Epoch 5 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:\n",
      "  Train Loss: 2.9586\n",
      "  Val Loss: 2.9861\n",
      "  Learning Rate: 2.50e-05\n",
      "‚úÖ Saved best model (val_loss: 2.9861)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:23<00:00,  3.35it/s]\n",
      "Epoch 6 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:\n",
      "  Train Loss: 2.9020\n",
      "  Val Loss: 2.9487\n",
      "  Learning Rate: 1.73e-05\n",
      "‚úÖ Saved best model (val_loss: 2.9487)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:23<00:00,  3.35it/s]\n",
      "Epoch 7 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:\n",
      "  Train Loss: 2.8679\n",
      "  Val Loss: 2.9265\n",
      "  Learning Rate: 1.03e-05\n",
      "‚úÖ Saved best model (val_loss: 2.9265)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:23<00:00,  3.36it/s]\n",
      "Epoch 8 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:\n",
      "  Train Loss: 2.8387\n",
      "  Val Loss: 2.9149\n",
      "  Learning Rate: 4.77e-06\n",
      "‚úÖ Saved best model (val_loss: 2.9149)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:23<00:00,  3.36it/s]\n",
      "Epoch 9 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:\n",
      "  Train Loss: 2.8204\n",
      "  Val Loss: 2.9103\n",
      "  Learning Rate: 1.22e-06\n",
      "‚úÖ Saved best model (val_loss: 2.9103)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 79/79 [00:23<00:00,  3.35it/s]\n",
      "Epoch 10 Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:07<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:\n",
      "  Train Loss: 2.8158\n",
      "  Val Loss: 2.9084\n",
      "  Learning Rate: 0.00e+00\n",
      "‚úÖ Saved best model (val_loss: 2.9084)\n",
      "üéâ Finetuning complete!\n",
      "Best validation loss: 2.9084\n",
      "Models saved to: ./music_transformer_workspace/finetuned_models\n"
     ]
    }
   ],
   "source": [
    "results = simple_complete_workflow(\n",
    "    train_dir=\"./train_data\",\n",
    "    test_dir=\"./test_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e2fe6ea-4df8-421b-87af-de4e700fe282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Generator loaded from ./music_transformer_workspace/finetuned_models/best_model.pt\n",
      "üéµ Generating music (prompt: 1 tokens)...\n",
      "Generated 884 tokens\n",
      "üéº MIDI saved to: ./music_transformer_workspace/generated_sample2.mid\n",
      "‚úÖ Simplified workflow complete!\n",
      "üìÅ Check for results\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Generate sample music\n",
    "generator, tokens = generate_music_with_finetuned_model(\n",
    "    model_path=\"./music_transformer_workspace/finetuned_models/best_model.pt\",\n",
    "    output_file=os.path.join(\"./music_transformer_workspace\", \"generated_sample2.mid\"),\n",
    "    temperature=0.8\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Simplified workflow complete!\")\n",
    "print(f\"üìÅ Check for results\")\n",
    "\n",
    "# return {\n",
    "#     'workspace': workspace,\n",
    "#     'model_path': model_path,\n",
    "#     'generator': generator\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d73b05f8-72ee-4987-8df4-e0aff7ce638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicTransformerGenerator:\n",
    "    \"\"\"Generate music with finetuned Music Transformer\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Load model and tokenizer\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        self.tokenizer = checkpoint['tokenizer']\n",
    "        \n",
    "        # Create and load model\n",
    "        self.model = MusicTransformerModel(vocab_size=self.tokenizer.vocab_size)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        print(f\"‚úÖ Generator loaded from {model_path}\")\n",
    "    \n",
    "    def generate(self, prompt=None, max_length=512, temperature=0.8, top_k=40, top_p=0.9, \n",
    "                 min_length=50, stop_on_end_token=True):\n",
    "        \"\"\"Generate music tokens with more control options\"\"\"\n",
    "        \n",
    "        if prompt is None:\n",
    "            prompt_tokens = [self.tokenizer.start_token]\n",
    "        else:\n",
    "            prompt_tokens = prompt if isinstance(prompt, list) else [prompt]\n",
    "        \n",
    "        # Encode prompt\n",
    "        token_ids = self.tokenizer.encode(prompt_tokens)\n",
    "        input_ids = torch.tensor([token_ids], device=self.device)\n",
    "        \n",
    "        print(f\"üéµ Generating music (prompt: {len(prompt_tokens)} tokens, target: {max_length} tokens)...\")\n",
    "        \n",
    "        generated_tokens = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for step in range(max_length):\n",
    "                # Forward pass\n",
    "                logits = self.model(input_ids)\n",
    "                next_token_logits = logits[0, -1, :] / temperature\n",
    "                \n",
    "                # Apply top-k and top-p filtering\n",
    "                if top_k > 0:\n",
    "                    top_k_logits, top_k_indices = torch.topk(next_token_logits, top_k)\n",
    "                    next_token_logits = torch.full_like(next_token_logits, float('-inf'))\n",
    "                    next_token_logits[top_k_indices] = top_k_logits\n",
    "                \n",
    "                if top_p < 1.0:\n",
    "                    sorted_logits, sorted_indices = torch.sort(next_token_logits, descending=True)\n",
    "                    cumulative_probs = torch.cumsum(torch.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "                    sorted_indices_to_remove = cumulative_probs > top_p\n",
    "                    sorted_indices_to_remove[1:] = sorted_indices_to_remove[:-1].clone()\n",
    "                    sorted_indices_to_remove[0] = 0\n",
    "                    next_token_logits[sorted_indices[sorted_indices_to_remove]] = float('-inf')\n",
    "                \n",
    "                # Sample next token\n",
    "                probs = torch.softmax(next_token_logits, dim=-1)\n",
    "                next_token = torch.multinomial(probs, 1)\n",
    "                \n",
    "                # Check for end token\n",
    "                next_token_str = self.tokenizer.id_to_token[next_token.item()]\n",
    "                \n",
    "                # Only stop on end token if we've generated enough tokens\n",
    "                if (next_token_str == self.tokenizer.end_token and \n",
    "                    stop_on_end_token and \n",
    "                    len(generated_tokens) >= min_length):\n",
    "                    print(f\"Stopped at step {step} (END token, min_length satisfied)\")\n",
    "                    break\n",
    "                \n",
    "                # Skip adding the end token but continue generating\n",
    "                if next_token_str != self.tokenizer.end_token:\n",
    "                    generated_tokens.append(next_token_str)\n",
    "                \n",
    "                # Update input (always add the token to context, even if it's end token)\n",
    "                input_ids = torch.cat([input_ids, next_token.unsqueeze(0)], dim=1)\n",
    "                \n",
    "                # Handle long sequences with sliding window\n",
    "                if input_ids.size(1) > 2048:\n",
    "                    input_ids = input_ids[:, -1024:]  # Keep last 1024 tokens\n",
    "                    print(f\"Applied sliding window at step {step}\")\n",
    "                \n",
    "                # Progress updates\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    print(f\"Generated {len(generated_tokens)} tokens so far...\")\n",
    "        \n",
    "        print(f\"‚úÖ Generated {len(generated_tokens)} tokens total\")\n",
    "        return generated_tokens\n",
    "    \n",
    "    def generate_midi(self, output_file, prompt=None, max_length=512, temperature=0.8, \n",
    "                     top_k=40, top_p=0.9, min_length=50, stop_on_end_token=True):\n",
    "        \"\"\"Generate and save MIDI file with more control\"\"\"\n",
    "        \n",
    "        # Generate tokens\n",
    "        tokens = self.generate(\n",
    "            prompt=prompt, \n",
    "            max_length=max_length, \n",
    "            temperature=temperature, \n",
    "            top_k=top_k, \n",
    "            top_p=top_p,\n",
    "            min_length=min_length,\n",
    "            stop_on_end_token=stop_on_end_token\n",
    "        )\n",
    "        \n",
    "        # Convert to MIDI\n",
    "        if prompt:\n",
    "            full_tokens = (prompt if isinstance(prompt, list) else [prompt]) + tokens\n",
    "        else:\n",
    "            full_tokens = [self.tokenizer.start_token] + tokens\n",
    "        \n",
    "        self.tokenizer.tokens_to_midi(full_tokens, output_file)\n",
    "        print(f\"üéº MIDI saved to: {output_file}\")\n",
    "        \n",
    "        return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38fe3a41-f223-42a1-afb5-e3ebbff83dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_long_music_piece(model_path, output_file, target_length=1000, \n",
    "                             temperature=0.8, overlap_tokens=50):\n",
    "    \"\"\"Generate very long music by combining multiple generations\"\"\"\n",
    "    \n",
    "    print(f\"üéº Generating long music piece with {target_length} tokens...\")\n",
    "    \n",
    "    generator = MusicTransformerGenerator(model_path)\n",
    "    all_tokens = []\n",
    "    \n",
    "    # Generate first chunk\n",
    "    print(\"üéµ Generating chunk 1...\")\n",
    "    chunk_tokens = generator.generate(\n",
    "        max_length=min(512, target_length),\n",
    "        temperature=temperature,\n",
    "        min_length=100,\n",
    "        stop_on_end_token=False  # Don't stop early\n",
    "    )\n",
    "    all_tokens.extend(chunk_tokens)\n",
    "    \n",
    "    # Generate additional chunks if needed\n",
    "    chunk_num = 2\n",
    "    while len(all_tokens) < target_length:\n",
    "        remaining = target_length - len(all_tokens)\n",
    "        chunk_size = min(512, remaining + overlap_tokens)\n",
    "        \n",
    "        print(f\"üéµ Generating chunk {chunk_num} (total so far: {len(all_tokens)} tokens)...\")\n",
    "        \n",
    "        # Use last N tokens as prompt for continuation\n",
    "        prompt_tokens = all_tokens[-overlap_tokens:] if len(all_tokens) >= overlap_tokens else all_tokens\n",
    "        \n",
    "        chunk_tokens = generator.generate(\n",
    "            prompt=prompt_tokens,\n",
    "            max_length=chunk_size,\n",
    "            temperature=temperature,\n",
    "            min_length=50,\n",
    "            stop_on_end_token=False\n",
    "        )\n",
    "        \n",
    "        # Add new tokens (skip overlap)\n",
    "        new_tokens = chunk_tokens[overlap_tokens:] if len(chunk_tokens) > overlap_tokens else chunk_tokens\n",
    "        all_tokens.extend(new_tokens)\n",
    "        \n",
    "        chunk_num += 1\n",
    "        \n",
    "        # Safety limit\n",
    "        if chunk_num > 10:\n",
    "            print(\"‚ö†Ô∏è  Reached chunk limit, stopping generation\")\n",
    "            break\n",
    "    \n",
    "    # Trim to exact target length\n",
    "    if len(all_tokens) > target_length:\n",
    "        all_tokens = all_tokens[:target_length]\n",
    "    \n",
    "    print(f\"‚úÖ Generated {len(all_tokens)} tokens total\")\n",
    "    \n",
    "    # Convert to MIDI\n",
    "    full_tokens = [generator.tokenizer.start_token] + all_tokens\n",
    "    generator.tokenizer.tokens_to_midi(full_tokens, output_file)\n",
    "    print(f\"üéº Long music piece saved to: {output_file}\")\n",
    "    \n",
    "    return all_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb01ec56-7f7d-4ffc-bac1-da91be181160",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_tokens = generate_long_music_piece(\n",
    "    model_path=\"./music_transformer_workspace/finetuned_models/best_model.pt\",\n",
    "    output_file=\"ops.mid\",\n",
    "    target_length=2000,       # Generate 2000 tokens!\n",
    "    temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f7e45d0-53c1-4b91-b7c6-fb73c7370767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfa03b1d-2bda-405b-bf3c-51b88e6470ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate against the model that is not fine tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e4f56b7-4a83-4117-b0bf-729cb8fb91bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tokenizer\n",
    "# !pip install masking\n",
    "# !pip install vocabulary\n",
    "# !pip install hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ccad3e-bad0-4d9c-9caf-865e5fb013fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate music with pretrained model\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "project_dir = \"music_transformer_workspace\"\n",
    "script_path = os.path.join(project_dir, \"generate.py\")\n",
    "model_path = os.path.join(project_dir, \"pretrained_models\", \"model6v2.pt\")\n",
    "music_path = os.path.join(project_dir, \"pretrained_sample.mid\")\n",
    "\n",
    "# Set environment with PYTHONPATH pointing to the project directory\n",
    "env = os.environ.copy()\n",
    "env[\"PYTHONPATH\"] = os.path.abspath(project_dir)\n",
    "\n",
    "# Run the script with the custom PYTHONPATH\n",
    "subprocess.run(\n",
    "    [\"python\", script_path, model_path, music_path],\n",
    "    env=env\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b348be1f-a390-4eb5-823e-68a18e579690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Loading MIDI files...\n",
      "Found 229 MIDI files\n",
      "üî§ Building tokenizer...\n",
      "Building vocabulary from MIDI files...\n",
      "Vocabulary size: 375\n",
      "üéµ Tokenizing MIDI files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<00:00, 226.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully tokenized 100 sequences\n",
      "üìä Creating datasets...\n",
      "Train dataset: 80 sequences\n",
      "Validation dataset: 20 sequences\n",
      "üöÄ Starting training...\n",
      "üîß Training simple transformer from scratch...\n",
      "Model parameters: 5,062,007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.82it/s]\n",
      "Epoch 1 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 4.9760, Val Loss = 3.9046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.80it/s]\n",
      "Epoch 2 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 4.0794, Val Loss = 3.3950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.81it/s]\n",
      "Epoch 3 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 3.6673, Val Loss = 3.0869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.79it/s]\n",
      "Epoch 4 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 3.3693, Val Loss = 2.8797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.74it/s]\n",
      "Epoch 5 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 3.1643, Val Loss = 2.7415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.72it/s]\n",
      "Epoch 6 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 3.0191, Val Loss = 2.6557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.82it/s]\n",
      "Epoch 7 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss = 2.9262, Val Loss = 2.5885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.74it/s]\n",
      "Epoch 8 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss = 2.8456, Val Loss = 2.5366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.79it/s]\n",
      "Epoch 9 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss = 2.7797, Val Loss = 2.4999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.82it/s]\n",
      "Epoch 10 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss = 2.7279, Val Loss = 2.4726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.88it/s]\n",
      "Epoch 11 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss = 2.6816, Val Loss = 2.4452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.80it/s]\n",
      "Epoch 12 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss = 2.6448, Val Loss = 2.4281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.80it/s]\n",
      "Epoch 13 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss = 2.6091, Val Loss = 2.4055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.82it/s]\n",
      "Epoch 14 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss = 2.5806, Val Loss = 2.3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.75it/s]\n",
      "Epoch 15 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss = 2.5514, Val Loss = 2.3755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.73it/s]\n",
      "Epoch 16 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss = 2.5271, Val Loss = 2.3656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.81it/s]\n",
      "Epoch 17 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss = 2.4992, Val Loss = 2.3538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.74it/s]\n",
      "Epoch 18 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss = 2.4779, Val Loss = 2.3450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.68it/s]\n",
      "Epoch 19 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss = 2.4538, Val Loss = 2.3342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.80it/s]\n",
      "Epoch 20 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss = 2.4299, Val Loss = 2.3316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.74it/s]\n",
      "Epoch 21 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss = 2.4096, Val Loss = 2.3214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.86it/s]\n",
      "Epoch 22 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss = 2.3864, Val Loss = 2.3168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.80it/s]\n",
      "Epoch 23 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss = 2.3662, Val Loss = 2.3193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.72it/s]\n",
      "Epoch 24 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss = 2.3468, Val Loss = 2.3095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.73it/s]\n",
      "Epoch 25 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss = 2.3255, Val Loss = 2.3097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.70it/s]\n",
      "Epoch 26 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss = 2.3032, Val Loss = 2.3023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.80it/s]\n",
      "Epoch 27 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss = 2.2876, Val Loss = 2.3025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.65it/s]\n",
      "Epoch 28 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss = 2.2624, Val Loss = 2.3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.75it/s]\n",
      "Epoch 29 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss = 2.2457, Val Loss = 2.3114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.77it/s]\n",
      "Epoch 30 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss = 2.2201, Val Loss = 2.3094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.71it/s]\n",
      "Epoch 31 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss = 2.2017, Val Loss = 2.3056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.76it/s]\n",
      "Epoch 32 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train Loss = 2.1826, Val Loss = 2.3105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.83it/s]\n",
      "Epoch 33 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss = 2.1617, Val Loss = 2.3098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.76it/s]\n",
      "Epoch 34 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss = 2.1399, Val Loss = 2.3148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.70it/s]\n",
      "Epoch 35 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train Loss = 2.1213, Val Loss = 2.3143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.69it/s]\n",
      "Epoch 36 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss = 2.1015, Val Loss = 2.3201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.69it/s]\n",
      "Epoch 37 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Train Loss = 2.0787, Val Loss = 2.3179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.83it/s]\n",
      "Epoch 38 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Train Loss = 2.0578, Val Loss = 2.3204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.69it/s]\n",
      "Epoch 39 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Train Loss = 2.0379, Val Loss = 2.3355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.68it/s]\n",
      "Epoch 40 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Train Loss = 2.0168, Val Loss = 2.3258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.65it/s]\n",
      "Epoch 41 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Train Loss = 1.9969, Val Loss = 2.3342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.75it/s]\n",
      "Epoch 42 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42: Train Loss = 1.9761, Val Loss = 2.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.69it/s]\n",
      "Epoch 43 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: Train Loss = 1.9600, Val Loss = 2.3524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.76it/s]\n",
      "Epoch 44 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: Train Loss = 1.9338, Val Loss = 2.3509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.76it/s]\n",
      "Epoch 45 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: Train Loss = 1.9143, Val Loss = 2.3505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.71it/s]\n",
      "Epoch 46 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: Train Loss = 1.8919, Val Loss = 2.3570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.69it/s]\n",
      "Epoch 47 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47: Train Loss = 1.8686, Val Loss = 2.3697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.71it/s]\n",
      "Epoch 48 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48: Train Loss = 1.8513, Val Loss = 2.3771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.76it/s]\n",
      "Epoch 49 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss = 1.8311, Val Loss = 2.3750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:05<00:00,  3.76it/s]\n",
      "Epoch 50 Val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: Train Loss = 1.8146, Val Loss = 2.3730\n",
      "Simple transformer training complete! Best val loss: 2.3023\n",
      "üéº Generating music...\n",
      "Saved: transformer_music.mid\n",
      "‚úÖ Complete! Check the generated MIDI files.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import torch.nn.functional as F\n",
    "# generate music with simple transformer model\n",
    "class SimpleMusicTransformer(torch.nn.Module):\n",
    "    \"\"\"Simple music transformer for comparison with GPT-2 approach\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, d_model=256, nhead=8, num_layers=6, max_seq_len=512):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Embeddings\n",
    "        self.token_embedding = torch.nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embedding = torch.nn.Embedding(max_seq_len, d_model)\n",
    "        \n",
    "        # Transformer layers\n",
    "        encoder_layer = torch.nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=0.1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = torch.nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Output projection\n",
    "        self.lm_head = torch.nn.Linear(d_model, vocab_size)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, input_ids, labels=None):\n",
    "        seq_len = input_ids.size(1)\n",
    "        \n",
    "        # Create embeddings\n",
    "        positions = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n",
    "        token_embeds = self.token_embedding(input_ids)\n",
    "        pos_embeds = self.pos_embedding(positions)\n",
    "        \n",
    "        x = self.dropout(token_embeds + pos_embeds)\n",
    "        \n",
    "        # Create causal mask\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
    "        \n",
    "        # Apply transformer\n",
    "        x = self.transformer(x, mask=mask.to(input_ids.device))\n",
    "        \n",
    "        # Get logits\n",
    "        logits = self.lm_head(x)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits.view(-1, self.vocab_size), labels.view(-1))\n",
    "        \n",
    "        return {'loss': loss, 'logits': logits}\n",
    "# # Simple MIDI Tokenizer\n",
    "class SimpleMIDITokenizer:\n",
    "    \"\"\"Simple tokenizer for MIDI data\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.token_to_id = {}\n",
    "        self.id_to_token = {}\n",
    "        self.vocab_size = 0\n",
    "        \n",
    "        # Special tokens\n",
    "        self.pad_token = \"<PAD>\"\n",
    "        self.sos_token = \"<SOS>\"  # Start of sequence\n",
    "        self.eos_token = \"<EOS>\"  # End of sequence\n",
    "        \n",
    "    def build_vocab(self, midi_files):\n",
    "        \"\"\"Build vocabulary from MIDI files\"\"\"\n",
    "        print(\"Building vocabulary from MIDI files...\")\n",
    "        \n",
    "        # Start with special tokens\n",
    "        tokens = [self.pad_token, self.sos_token, self.eos_token]\n",
    "        \n",
    "        # Add note tokens (note_on, note_off, time_shift)\n",
    "        for pitch in range(128):  # MIDI pitch range\n",
    "            tokens.append(f\"note_on_{pitch}\")\n",
    "            tokens.append(f\"note_off_{pitch}\")\n",
    "        \n",
    "        # Add time shift tokens (in 10ms increments up to 1 second)\n",
    "        for time_shift in range(1, 101):  # 10ms to 1000ms\n",
    "            tokens.append(f\"time_shift_{time_shift}\")\n",
    "        \n",
    "        # Add velocity tokens\n",
    "        for velocity in range(1, 128, 8):  # Quantized velocities\n",
    "            tokens.append(f\"velocity_{velocity}\")\n",
    "            \n",
    "        # Create mappings\n",
    "        self.token_to_id = {token: i for i, token in enumerate(tokens)}\n",
    "        self.id_to_token = {i: token for i, token in enumerate(tokens)}\n",
    "        self.vocab_size = len(tokens)\n",
    "        \n",
    "        print(f\"Vocabulary size: {self.vocab_size}\")\n",
    "        \n",
    "    def midi_to_tokens(self, midi_file_path):\n",
    "        \"\"\"Convert MIDI file to token sequence\"\"\"\n",
    "        try:\n",
    "            midi = pretty_midi.PrettyMIDI(midi_file_path)\n",
    "            tokens = [self.sos_token]\n",
    "            \n",
    "            # Get all note events\n",
    "            events = []\n",
    "            for instrument in midi.instruments:\n",
    "                if instrument.is_drum:\n",
    "                    continue\n",
    "                    \n",
    "                for note in instrument.notes:\n",
    "                    events.append(('note_on', note.start, note.pitch, note.velocity))\n",
    "                    events.append(('note_off', note.end, note.pitch, 0))\n",
    "            \n",
    "            # Sort by time\n",
    "            events.sort(key=lambda x: x[1])\n",
    "            \n",
    "            current_time = 0\n",
    "            current_velocity = 64\n",
    "            \n",
    "            for event_type, time, pitch, velocity in events:\n",
    "                # Add time shift if needed\n",
    "                time_diff = time - current_time\n",
    "                if time_diff > 0:\n",
    "                    # Quantize to 10ms increments\n",
    "                    time_shift = min(int(time_diff * 100), 100)\n",
    "                    if time_shift > 0:\n",
    "                        tokens.append(f\"time_shift_{time_shift}\")\n",
    "                \n",
    "                # Add velocity change if needed (for note_on events)\n",
    "                if event_type == 'note_on' and velocity != current_velocity:\n",
    "                    # Quantize velocity\n",
    "                    quant_velocity = (velocity // 8) * 8 + 1\n",
    "                    tokens.append(f\"velocity_{quant_velocity}\")\n",
    "                    current_velocity = velocity\n",
    "                \n",
    "                # Add note event\n",
    "                tokens.append(f\"{event_type}_{pitch}\")\n",
    "                current_time = time\n",
    "            \n",
    "            tokens.append(self.eos_token)\n",
    "            return tokens\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {midi_file_path}: {e}\")\n",
    "            return [self.sos_token, self.eos_token]\n",
    "    \n",
    "    def tokens_to_midi(self, tokens, output_path, tempo=120):\n",
    "        \"\"\"Convert token sequence back to MIDI file\"\"\"\n",
    "        midi = pretty_midi.PrettyMIDI(initial_tempo=tempo)\n",
    "        instrument = pretty_midi.Instrument(program=0)  # Piano\n",
    "        \n",
    "        current_time = 0\n",
    "        current_velocity = 64\n",
    "        active_notes = {}  # pitch -> start_time\n",
    "        \n",
    "        for token in tokens:\n",
    "            if token.startswith('time_shift_'):\n",
    "                shift = int(token.split('_')[2])\n",
    "                current_time += shift / 100.0  # Convert back to seconds\n",
    "                \n",
    "            elif token.startswith('velocity_'):\n",
    "                current_velocity = int(token.split('_')[1])\n",
    "                \n",
    "            elif token.startswith('note_on_'):\n",
    "                pitch = int(token.split('_')[2])\n",
    "                active_notes[pitch] = current_time\n",
    "                \n",
    "            elif token.startswith('note_off_'):\n",
    "                pitch = int(token.split('_')[2])\n",
    "                if pitch in active_notes:\n",
    "                    start_time = active_notes[pitch]\n",
    "                    note = pretty_midi.Note(\n",
    "                        velocity=current_velocity,\n",
    "                        pitch=pitch,\n",
    "                        start=start_time,\n",
    "                        end=current_time\n",
    "                    )\n",
    "                    instrument.notes.append(note)\n",
    "                    del active_notes[pitch]\n",
    "        \n",
    "        # Close any remaining active notes\n",
    "        for pitch, start_time in active_notes.items():\n",
    "            note = pretty_midi.Note(\n",
    "                velocity=current_velocity,\n",
    "                pitch=pitch,\n",
    "                start=start_time,\n",
    "                end=current_time + 0.5  # 500ms default note length\n",
    "            )\n",
    "            instrument.notes.append(note)\n",
    "        \n",
    "        midi.instruments.append(instrument)\n",
    "        midi.write(output_path)\n",
    "\n",
    "# Dataset class\n",
    "class MIDIDataset(Dataset):\n",
    "    def __init__(self, tokenized_sequences, tokenizer, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.sequences = []\n",
    "        \n",
    "        # Convert tokens to IDs and prepare sequences\n",
    "        for tokens in tokenized_sequences:\n",
    "            if len(tokens) > 2:  # Must have more than just SOS/EOS\n",
    "                # Convert to IDs\n",
    "                token_ids = [tokenizer.token_to_id.get(token, 0) for token in tokens]\n",
    "                \n",
    "                # Truncate if too long\n",
    "                if len(token_ids) > max_length:\n",
    "                    token_ids = token_ids[:max_length]\n",
    "                \n",
    "                self.sequences.append(token_ids)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        \n",
    "        # Pad sequence\n",
    "        padded_seq = seq + [0] * (self.max_length - len(seq))\n",
    "        padded_seq = padded_seq[:self.max_length]\n",
    "        \n",
    "        # Input is sequence without last token, labels is sequence without first token\n",
    "        input_ids = torch.tensor(padded_seq[:-1], dtype=torch.long)\n",
    "        labels = torch.tensor(padded_seq[1:], dtype=torch.long)\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "# Training function (paste your provided function here)\n",
    "def train_simple_transformer(train_dataset, val_dataset, tokenizer, output_dir, epochs):\n",
    "    \"\"\"Train a simple transformer from scratch for comparison\"\"\"\n",
    "    \n",
    "    print(\"üîß Training simple transformer from scratch...\")\n",
    "    \n",
    "    # Create model\n",
    "    model = SimpleMusicTransformer(vocab_size=tokenizer.vocab_size)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} Train\"):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, labels=labels)\n",
    "            loss = outputs['loss']\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1} Val\"):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids, labels=labels)\n",
    "                val_loss += outputs['loss'].item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            torch.save(model.state_dict(), os.path.join(output_dir, 'model.pt'))\n",
    "            \n",
    "            # Save tokenizer and config\n",
    "            with open(os.path.join(output_dir, 'tokenizer.pkl'), 'wb') as f:\n",
    "                pickle.dump(tokenizer, f)\n",
    "            \n",
    "            config = {\n",
    "                'vocab_size': tokenizer.vocab_size,\n",
    "                'd_model': model.d_model,\n",
    "                'approach': 'simple_transformer'\n",
    "            }\n",
    "            with open(os.path.join(output_dir, 'config.json'), 'w') as f:\n",
    "                json.dump(config, f, indent=2)\n",
    "    \n",
    "    # Save training history\n",
    "    history = {'train_losses': train_losses, 'val_losses': val_losses, 'best_val_loss': best_val_loss}\n",
    "    with open(os.path.join(output_dir, 'history.json'), 'w') as f:\n",
    "        json.dump(history, f, indent=2)\n",
    "    \n",
    "    print(f\"Simple transformer training complete! Best val loss: {best_val_loss:.4f}\")\n",
    "    return output_dir\n",
    "\n",
    "def generate_music(model, tokenizer, prompt_tokens=None, max_length=512, temperature=1.0, top_k=50):\n",
    "    \"\"\"Generate music using the trained model\"\"\"\n",
    "    device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    \n",
    "    # Start with SOS token or provided prompt\n",
    "    if prompt_tokens is None:\n",
    "        generated = [tokenizer.token_to_id[tokenizer.sos_token]]\n",
    "    else:\n",
    "        generated = [tokenizer.token_to_id.get(token, 0) for token in prompt_tokens]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length - len(generated)):\n",
    "            # Convert to tensor\n",
    "            input_ids = torch.tensor([generated], dtype=torch.long).to(device)\n",
    "            \n",
    "            # Get predictions\n",
    "            outputs = model(input_ids)\n",
    "            logits = outputs['logits'][0, -1, :]  # Last token logits\n",
    "            \n",
    "            # Apply temperature\n",
    "            logits = logits / temperature\n",
    "            \n",
    "            # Apply top-k filtering\n",
    "            if top_k > 0:\n",
    "                top_k_logits, top_k_indices = torch.topk(logits, top_k)\n",
    "                logits = torch.full_like(logits, float('-inf'))\n",
    "                logits[top_k_indices] = top_k_logits\n",
    "            \n",
    "            # Sample next token\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1).item()\n",
    "            \n",
    "            # Stop if EOS token\n",
    "            if next_token == tokenizer.token_to_id.get(tokenizer.eos_token, -1):\n",
    "                break\n",
    "                \n",
    "            generated.append(next_token)\n",
    "    \n",
    "    # Convert back to tokens\n",
    "    generated_tokens = [tokenizer.id_to_token.get(id, \"<UNK>\") for id in generated]\n",
    "    return generated_tokens\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the complete pipeline\"\"\"\n",
    "    \n",
    "    # 1. Prepare data\n",
    "    print(\"üìÅ Loading MIDI files...\")\n",
    "    # You need to specify your MIDI files directory\n",
    "    midi_dir = \"train_data\"  # Change this to your MIDI directory\n",
    "    \n",
    "    # For demonstration, create some dummy data if no MIDI files found\n",
    "    midi_files = glob.glob(os.path.join(midi_dir, \"*.mid\")) + glob.glob(os.path.join(midi_dir, \"*.midi\"))\n",
    "    \n",
    "    if not midi_files:\n",
    "        print(\"‚ö†Ô∏è  No MIDI files found. Please update 'midi_dir' variable with your MIDI files path.\")\n",
    "        print(\"For now, creating a simple demonstration with minimal data...\")\n",
    "        # You can continue with demo data or return here\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(midi_files)} MIDI files\")\n",
    "    \n",
    "    # 2. Create tokenizer and build vocabulary\n",
    "    print(\"üî§ Building tokenizer...\")\n",
    "    tokenizer = SimpleMIDITokenizer()\n",
    "    tokenizer.build_vocab(midi_files)\n",
    "    \n",
    "    # 3. Tokenize MIDI files\n",
    "    print(\"üéµ Tokenizing MIDI files...\")\n",
    "    tokenized_sequences = []\n",
    "    for midi_file in tqdm(midi_files[:100]):  # Limit to first 100 files for demo\n",
    "        tokens = tokenizer.midi_to_tokens(midi_file)\n",
    "        if len(tokens) > 10:  # Only use sequences with some content\n",
    "            tokenized_sequences.append(tokens)\n",
    "    \n",
    "    print(f\"Successfully tokenized {len(tokenized_sequences)} sequences\")\n",
    "    \n",
    "    # 4. Create datasets\n",
    "    print(\"üìä Creating datasets...\")\n",
    "    # Split into train/val\n",
    "    split_idx = int(0.8 * len(tokenized_sequences))\n",
    "    train_sequences = tokenized_sequences[:split_idx]\n",
    "    val_sequences = tokenized_sequences[split_idx:]\n",
    "    \n",
    "    train_dataset = MIDIDataset(train_sequences, tokenizer)\n",
    "    val_dataset = MIDIDataset(val_sequences, tokenizer)\n",
    "    \n",
    "    print(f\"Train dataset: {len(train_dataset)} sequences\")\n",
    "    print(f\"Validation dataset: {len(val_dataset)} sequences\")\n",
    "    \n",
    "    # 5. Train model\n",
    "    print(\"üöÄ Starting training...\")\n",
    "    output_dir = \"./simple_transformer_model\"\n",
    "    train_simple_transformer(train_dataset, val_dataset, tokenizer, output_dir, epochs=50)\n",
    "    \n",
    "    # 6. Load trained model and generate music\n",
    "    print(\"üéº Generating music...\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Load model\n",
    "    model = SimpleMusicTransformer(vocab_size=tokenizer.vocab_size)\n",
    "    model.load_state_dict(torch.load(os.path.join(output_dir, 'model.pt'), map_location=device))\n",
    "    model.to(device)\n",
    "    \n",
    "\n",
    "\n",
    "    generated_tokens = gen_music(\n",
    "        model, tokenizer, \n",
    "        max_length=200, \n",
    "        temperature=0.8, \n",
    "        top_k=40\n",
    "    )\n",
    "    \n",
    "    # Convert to MIDI\n",
    "    output_midi_path = f\"transformer_music.mid\"\n",
    "    tokenizer.tokens_to_midi(generated_tokens, output_midi_path)\n",
    "    print(f\"Saved: {output_midi_path}\")\n",
    "    \n",
    "    print(\"‚úÖ Complete! Check the generated MIDI files.\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e09ddc-3ca5-4e47-ad82-e6b8e85c32ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's compare the 3 different models music that they generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e758e2ba-1041-4238-b87a-a1a439366c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get statistics of test midi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a1dd000-bb94-4bd8-b6a6-b9b1c32f8a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import wasserstein_distance\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4fc5539-10ec-468a-a52a-341376db5a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDIEvaluator:\n",
    "    \"\"\"Comprehensive MIDI evaluation metrics for music generation\"\"\"\n",
    "    \n",
    "    def __init__(self, test_midi_dir):\n",
    "        \"\"\"Initialize with directory containing test/reference MIDI files\"\"\"\n",
    "        self.test_midi_dir = test_midi_dir\n",
    "        self.test_files = glob.glob(os.path.join(test_midi_dir, \"*.mid\")) + \\\n",
    "                         glob.glob(os.path.join(test_midi_dir, \"*.midi\"))\n",
    "        \n",
    "        print(f\"Found {len(self.test_files)} test MIDI files for reference\")\n",
    "        \n",
    "        # Precompute test set statistics\n",
    "        self.test_stats = self._compute_test_statistics()\n",
    "    \n",
    "    def _extract_notes_from_midi(self, midi_path):\n",
    "        \"\"\"Extract note information from MIDI file\"\"\"\n",
    "        try:\n",
    "            midi = pretty_midi.PrettyMIDI(midi_path)\n",
    "            notes = []\n",
    "            \n",
    "            for instrument in midi.instruments:\n",
    "                if not instrument.is_drum:  # Skip drum tracks\n",
    "                    for note in instrument.notes:\n",
    "                        notes.append({\n",
    "                            'pitch': note.pitch,\n",
    "                            'start': note.start,\n",
    "                            'end': note.end,\n",
    "                            'duration': note.end - note.start,\n",
    "                            'velocity': note.velocity\n",
    "                        })\n",
    "            \n",
    "            return sorted(notes, key=lambda x: x['start'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {midi_path}: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _compute_test_statistics(self):\n",
    "        \"\"\"Precompute statistics from test set\"\"\"\n",
    "        print(\"Computing test set statistics...\")\n",
    "        \n",
    "        all_pitch_classes = []\n",
    "        all_intervals = []\n",
    "        all_note_densities = []\n",
    "        all_durations = []\n",
    "        \n",
    "        processed_files = 0\n",
    "        \n",
    "        for midi_file in self.test_files:\n",
    "            notes = self._extract_notes_from_midi(midi_file)\n",
    "            if len(notes) < 5:  # Skip files with too few notes\n",
    "                continue\n",
    "                \n",
    "            processed_files += 1\n",
    "            \n",
    "            # Pitch classes (0-11)\n",
    "            pitch_classes = [note['pitch'] % 12 for note in notes]\n",
    "            all_pitch_classes.extend(pitch_classes)\n",
    "            \n",
    "            # Melodic intervals\n",
    "            pitches = [note['pitch'] for note in notes]\n",
    "            intervals = [pitches[i+1] - pitches[i] for i in range(len(pitches)-1)]\n",
    "            all_intervals.extend(intervals)\n",
    "            \n",
    "            # Note density (notes per second)\n",
    "            if notes:\n",
    "                total_time = max(note['end'] for note in notes)\n",
    "                if total_time > 0:\n",
    "                    density = len(notes) / total_time\n",
    "                    all_note_densities.append(density)\n",
    "            \n",
    "            # Note durations\n",
    "            durations = [note['duration'] for note in notes if note['duration'] > 0]\n",
    "            all_durations.extend(durations)\n",
    "        \n",
    "        print(f\"Processed {processed_files} valid MIDI files from test set\")\n",
    "        \n",
    "        # Handle edge case where no valid files were processed\n",
    "        if processed_files == 0:\n",
    "            print(\"‚ö†Ô∏è  Warning: No valid test files found. Using default distributions.\")\n",
    "            return {\n",
    "                'pitch_class_dist': np.ones(12) / 12,  # Uniform distribution\n",
    "                'interval_dist': np.ones(48) / 48,     # Uniform distribution\n",
    "                'note_density_mean': 5.0,              # Default density\n",
    "                'note_density_std': 1.0,               # Default std\n",
    "                'duration_dist': np.ones(19) / 19      # Uniform distribution\n",
    "            }\n",
    "        \n",
    "        # Create normalized pitch class distribution\n",
    "        if all_pitch_classes:\n",
    "            pitch_dist = np.bincount(all_pitch_classes, minlength=12).astype(float)\n",
    "            pitch_dist += 1e-10  # Small epsilon\n",
    "            pitch_dist = pitch_dist / pitch_dist.sum()\n",
    "        else:\n",
    "            pitch_dist = np.ones(12) / 12\n",
    "        \n",
    "        return {\n",
    "            'pitch_class_dist': pitch_dist,\n",
    "            'interval_dist': self._create_interval_distribution(all_intervals),\n",
    "            'note_density_mean': np.mean(all_note_densities) if all_note_densities else 5.0,\n",
    "            'note_density_std': np.std(all_note_densities) if all_note_densities else 1.0,\n",
    "            'duration_dist': self._create_duration_distribution(all_durations)\n",
    "        }\n",
    "    \n",
    "    def _create_interval_distribution(self, intervals):\n",
    "        \"\"\"Create distribution of melodic intervals\"\"\"\n",
    "        if not intervals:\n",
    "            return np.ones(48) / 48  # Uniform distribution as fallback\n",
    "        \n",
    "        # Bin intervals from -24 to +24 semitones\n",
    "        interval_bins = np.arange(-24, 25)\n",
    "        hist, _ = np.histogram(intervals, bins=interval_bins, density=False)\n",
    "        \n",
    "        # Normalize and add small epsilon to avoid zero probabilities\n",
    "        hist = hist.astype(float)\n",
    "        hist += 1e-10  # Small epsilon\n",
    "        hist = hist / hist.sum()\n",
    "        \n",
    "        return hist\n",
    "    \n",
    "    def _create_duration_distribution(self, durations):\n",
    "        \"\"\"Create distribution of note durations\"\"\"\n",
    "        if not durations:\n",
    "            return np.ones(19) / 19  # Uniform distribution as fallback\n",
    "        \n",
    "        # Bin durations into reasonable buckets (in seconds)\n",
    "        duration_bins = np.logspace(-2, 1, 20)  # 0.01s to 10s\n",
    "        hist, _ = np.histogram(durations, bins=duration_bins, density=False)\n",
    "        \n",
    "        # Normalize and add small epsilon to avoid zero probabilities\n",
    "        hist = hist.astype(float)\n",
    "        hist += 1e-10  # Small epsilon\n",
    "        hist = hist / hist.sum()\n",
    "        \n",
    "        return hist\n",
    "    \n",
    "    def metric_1_harmonic_similarity(self, midi_file):\n",
    "        \"\"\"\n",
    "        Metric 1: Harmonic Similarity Score\n",
    "        Measures how similar the harmonic content is to real music\n",
    "        Higher scores = better (more similar to test set)\n",
    "        \"\"\"\n",
    "        notes = self._extract_notes_from_midi(midi_file)\n",
    "        if len(notes) < 5:\n",
    "            return 0.0  # Minimum similarity for insufficient data\n",
    "        \n",
    "        # Get pitch class distribution\n",
    "        pitch_classes = [note['pitch'] % 12 for note in notes]\n",
    "        if not pitch_classes:\n",
    "            return 0.0\n",
    "        \n",
    "        # Create normalized distribution with small epsilon\n",
    "        generated_dist = np.bincount(pitch_classes, minlength=12).astype(float)\n",
    "        generated_dist += 1e-10  # Small epsilon to avoid zeros\n",
    "        generated_dist = generated_dist / generated_dist.sum()\n",
    "        \n",
    "        # Ensure test distribution is also properly normalized\n",
    "        test_dist = self.test_stats['pitch_class_dist'].copy()\n",
    "        test_dist += 1e-10\n",
    "        test_dist = test_dist / test_dist.sum()\n",
    "        \n",
    "        # Jensen-Shannon divergence with test set, then convert to similarity\n",
    "        try:\n",
    "            js_distance = jensenshannon(generated_dist, test_dist)\n",
    "            if np.isnan(js_distance):\n",
    "                return 0.0\n",
    "            # Convert distance to similarity (0-1, higher = better)\n",
    "            similarity = 1.0 - js_distance\n",
    "            return max(0.0, similarity)\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    def metric_2_rhythmic_consistency(self, midi_file):\n",
    "        \"\"\"\n",
    "        Metric 2: Rhythmic Consistency Score\n",
    "        Measures how consistent and musical the timing patterns are\n",
    "        Higher scores = better (more consistent rhythm)\n",
    "        \"\"\"\n",
    "        notes = self._extract_notes_from_midi(midi_file)\n",
    "        if len(notes) < 10:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate inter-onset intervals (IOIs)\n",
    "        onset_times = [note['start'] for note in notes]\n",
    "        iois = [onset_times[i+1] - onset_times[i] for i in range(len(onset_times)-1)]\n",
    "        \n",
    "        if not iois:\n",
    "            return 0.0\n",
    "        \n",
    "        # Score based on rhythmic regularity\n",
    "        ioi_std = np.std(iois)\n",
    "        ioi_mean = np.mean(iois)\n",
    "        \n",
    "        # Penalize extremely irregular or extremely regular rhythms\n",
    "        regularity_score = 1.0 / (1.0 + ioi_std / max(ioi_mean, 0.01))\n",
    "        \n",
    "        # Check for musical note durations (prefer common divisions)\n",
    "        common_durations = [0.125, 0.25, 0.5, 1.0, 2.0]  # 16th, 8th, quarter, half, whole notes (120 BPM)\n",
    "        duration_scores = []\n",
    "        \n",
    "        for ioi in iois:\n",
    "            closest_musical = min(common_durations, key=lambda x: abs(x - ioi))\n",
    "            score = 1.0 / (1.0 + abs(ioi - closest_musical))\n",
    "            duration_scores.append(score)\n",
    "        \n",
    "        musical_score = np.mean(duration_scores)\n",
    "        \n",
    "        # Combined score (0-1, higher is better)\n",
    "        return 0.7 * regularity_score + 0.3 * musical_score\n",
    "    \n",
    "    def metric_3_scale_consistency(self, midi_file):\n",
    "        \"\"\"\n",
    "        Metric 3: Scale Consistency Score\n",
    "        Measures how well the notes stay within a consistent musical scale\n",
    "        Higher scores = better (more consistent scale usage)\n",
    "        \"\"\"\n",
    "        notes = self._extract_notes_from_midi(midi_file)\n",
    "        if len(notes) < 5:\n",
    "            return 0.0\n",
    "        \n",
    "        # Get all pitch classes used in the piece\n",
    "        pitch_classes = [note['pitch'] % 12 for note in notes]\n",
    "        unique_pitches = set(pitch_classes)\n",
    "        \n",
    "        if len(unique_pitches) < 3:  # Too few notes to determine scale\n",
    "            return 0.5\n",
    "        \n",
    "        # Define common scales (in pitch class numbers)\n",
    "        scales = {\n",
    "            # Major scales (all 12 keys)\n",
    "            'C_major': {0, 2, 4, 5, 7, 9, 11},\n",
    "            'C#_major': {1, 3, 5, 6, 8, 10, 0},\n",
    "            'D_major': {2, 4, 6, 7, 9, 11, 1},\n",
    "            'Eb_major': {3, 5, 7, 8, 10, 0, 2},\n",
    "            'E_major': {4, 6, 8, 9, 11, 1, 3},\n",
    "            'F_major': {5, 7, 9, 10, 0, 2, 4},\n",
    "            'F#_major': {6, 8, 10, 11, 1, 3, 5},\n",
    "            'G_major': {7, 9, 11, 0, 2, 4, 6},\n",
    "            'Ab_major': {8, 10, 0, 1, 3, 5, 7},\n",
    "            'A_major': {9, 11, 1, 2, 4, 6, 8},\n",
    "            'Bb_major': {10, 0, 2, 3, 5, 7, 9},\n",
    "            'B_major': {11, 1, 3, 4, 6, 8, 10},\n",
    "            \n",
    "            # Minor scales (natural minor, all 12 keys)\n",
    "            'C_minor': {0, 2, 3, 5, 7, 8, 10},\n",
    "            'C#_minor': {1, 3, 4, 6, 8, 9, 11},\n",
    "            'D_minor': {2, 4, 5, 7, 9, 10, 0},\n",
    "            'Eb_minor': {3, 5, 6, 8, 10, 11, 1},\n",
    "            'E_minor': {4, 6, 7, 9, 11, 0, 2},\n",
    "            'F_minor': {5, 7, 8, 10, 0, 1, 3},\n",
    "            'F#_minor': {6, 8, 9, 11, 1, 2, 4},\n",
    "            'G_minor': {7, 9, 10, 0, 2, 3, 5},\n",
    "            'Ab_minor': {8, 10, 11, 1, 3, 4, 6},\n",
    "            'A_minor': {9, 11, 0, 2, 4, 5, 7},\n",
    "            'Bb_minor': {10, 0, 1, 3, 5, 6, 8},\n",
    "            'B_minor': {11, 1, 2, 4, 6, 7, 9},\n",
    "            \n",
    "            # # Pentatonic scales\n",
    "            # 'C_pentatonic': {0, 2, 4, 7, 9},\n",
    "            # 'D_pentatonic': {2, 4, 6, 9, 11},\n",
    "            # 'E_pentatonic': {4, 6, 8, 11, 1},\n",
    "            # 'F_pentatonic': {5, 7, 9, 0, 2},\n",
    "            # 'G_pentatonic': {7, 9, 11, 2, 4},\n",
    "            # 'A_pentatonic': {9, 11, 1, 4, 6},\n",
    "            # 'B_pentatonic': {11, 1, 3, 6, 8},\n",
    "        }\n",
    "        \n",
    "        # Find the best fitting scale\n",
    "        best_score = 0\n",
    "        best_scale = None\n",
    "        \n",
    "        for scale_name, scale_notes in scales.items():\n",
    "            # Calculate how many notes fit this scale\n",
    "            fitting_notes = unique_pitches.intersection(scale_notes)\n",
    "            non_fitting_notes = unique_pitches - scale_notes\n",
    "            \n",
    "            # Score: percentage of notes that fit + penalty for non-fitting notes\n",
    "            fit_ratio = len(fitting_notes) / len(unique_pitches)\n",
    "            penalty = len(non_fitting_notes) * 0.1  # Penalty for each non-scale note\n",
    "            \n",
    "            score = fit_ratio - penalty\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_scale = scale_name\n",
    "        \n",
    "        # Additional scoring based on note frequency (not just presence)\n",
    "        if best_scale:\n",
    "            scale_notes = scales[best_scale]\n",
    "            \n",
    "            # Weight by how often each note appears\n",
    "            scale_note_count = sum(1 for pc in pitch_classes if pc in scale_notes)\n",
    "            total_notes = len(pitch_classes)\n",
    "            \n",
    "            frequency_score = scale_note_count / total_notes\n",
    "            \n",
    "            # Combine presence-based and frequency-based scores\n",
    "            final_score = 0.6 * max(best_score, 0) + 0.4 * frequency_score\n",
    "        else:\n",
    "            final_score = 0.0\n",
    "        \n",
    "        # Bonus for using a reasonable number of scale notes (not too few, not too many)\n",
    "        num_unique = len(unique_pitches)\n",
    "        if 4 <= num_unique <= 7:  # Typical for good melodies\n",
    "            completeness_bonus = 0.1\n",
    "        else:\n",
    "            completeness_bonus = 0.0\n",
    "        \n",
    "        return min(1.0, final_score + completeness_bonus)\n",
    "    \n",
    "    def metric_4_musical_structure_score(self, midi_file):\n",
    "        \"\"\"\n",
    "        Metric 4: Musical Structure Score\n",
    "        Evaluates note density, duration patterns, and overall musical structure\n",
    "        Higher scores = better (more musical structure)\n",
    "        \"\"\"\n",
    "        notes = self._extract_notes_from_midi(midi_file)\n",
    "        if len(notes) < 5:\n",
    "            return 0.0\n",
    "        \n",
    "        # Note density score\n",
    "        total_time = max(note['end'] for note in notes) if notes else 1\n",
    "        if total_time <= 0:\n",
    "            return 0.0\n",
    "            \n",
    "        note_density = len(notes) / total_time\n",
    "        \n",
    "        # Score based on similarity to test set density\n",
    "        test_density = max(self.test_stats['note_density_mean'], 0.1)\n",
    "        density_diff = abs(note_density - test_density)\n",
    "        density_score = 1.0 / (1.0 + density_diff / test_density)\n",
    "        \n",
    "        # Duration distribution score\n",
    "        durations = [note['duration'] for note in notes if note['duration'] > 0]\n",
    "        if durations:\n",
    "            generated_duration_dist = self._create_duration_distribution(durations)\n",
    "            test_duration_dist = self.test_stats['duration_dist']\n",
    "            \n",
    "            try:\n",
    "                # Jensen-Shannon similarity\n",
    "                js_dist = jensenshannon(generated_duration_dist, test_duration_dist)\n",
    "                duration_similarity = 1 - js_dist if not np.isnan(js_dist) else 0.0\n",
    "            except:\n",
    "                duration_similarity = 0.0\n",
    "        else:\n",
    "            duration_similarity = 0.0\n",
    "        \n",
    "        # Pitch range score (penalize too narrow or too wide ranges)\n",
    "        pitches = [note['pitch'] for note in notes]\n",
    "        if pitches:\n",
    "            pitch_range = max(pitches) - min(pitches)\n",
    "            optimal_range = 24  # 2 octaves\n",
    "            range_score = 1.0 / (1.0 + abs(pitch_range - optimal_range) / max(optimal_range, 1))\n",
    "        else:\n",
    "            range_score = 0.0\n",
    "        \n",
    "        # Combined score\n",
    "        return 0.4 * density_score + 0.4 * duration_similarity + 0.2 * range_score\n",
    "    \n",
    "    def evaluate_midi_file(self, midi_file):\n",
    "        \"\"\"Evaluate a single MIDI file on all metrics\"\"\"\n",
    "        results = {\n",
    "            'file': os.path.basename(midi_file),\n",
    "            'harmonic_similarity': self.metric_1_harmonic_similarity(midi_file),\n",
    "            'rhythmic_consistency': self.metric_2_rhythmic_consistency(midi_file),\n",
    "            'scale_consistency': self.metric_3_scale_consistency(midi_file),\n",
    "            'musical_structure': self.metric_4_musical_structure_score(midi_file)\n",
    "        }\n",
    "        return results\n",
    "    \n",
    "    def compare_midi_files(self, generated_files):\n",
    "        \"\"\"Compare multiple generated MIDI files\"\"\"\n",
    "        print(f\"\\nüéµ Evaluating {len(generated_files)} generated MIDI files...\\n\")\n",
    "        \n",
    "        results = []\n",
    "        for midi_file in generated_files:\n",
    "            if os.path.exists(midi_file):\n",
    "                result = self.evaluate_midi_file(midi_file)\n",
    "                results.append(result)\n",
    "                print(f\"üìä {result['file']}:\")\n",
    "                print(f\"   Harmonic Similarity: {result['harmonic_similarity']:.4f} (higher = better)\")\n",
    "                print(f\"   Rhythmic Consistency: {result['rhythmic_consistency']:.4f} (higher = better)\")\n",
    "                print(f\"   Scale Consistency: {result['scale_consistency']:.4f} (higher = better)\")\n",
    "                print(f\"   Musical Structure: {result['musical_structure']:.4f} (higher = better)\")\n",
    "                print()\n",
    "            else:\n",
    "                print(f\"‚ùå File not found: {midi_file}\")\n",
    "        \n",
    "        # Rank files\n",
    "        if results:\n",
    "            self._rank_files(results)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _rank_files(self, results):\n",
    "        \"\"\"Rank files based on composite score\"\"\"\n",
    "        print(\"üèÜ RANKING (Best to Worst):\\n\")\n",
    "        \n",
    "        # Create composite score (all metrics now higher = better)\n",
    "        for result in results:\n",
    "            # All metrics are now higher = better, so simple average\n",
    "            composite = (\n",
    "                0.25 * result['harmonic_similarity'] +     # Harmonic similarity\n",
    "                0.25 * result['rhythmic_consistency'] +    # Rhythmic quality\n",
    "                0.25 * result['scale_consistency'] +       # Scale consistency\n",
    "                0.25 * result['musical_structure']         # Overall structure\n",
    "            )\n",
    "            \n",
    "            result['composite_score'] = composite\n",
    "        \n",
    "        # Sort by composite score (descending)\n",
    "        ranked = sorted(results, key=lambda x: x['composite_score'], reverse=True)\n",
    "        \n",
    "        for i, result in enumerate(ranked, 1):\n",
    "            print(f\"{i}. {result['file']}\")\n",
    "            print(f\"   Overall Score: {result['composite_score']:.4f}\")\n",
    "            print(f\"   Best aspects: \", end=\"\")\n",
    "            \n",
    "            # Identify strengths (all metrics higher = better now)\n",
    "            strengths = []\n",
    "            if result['rhythmic_consistency'] > 0.6:\n",
    "                strengths.append(\"Good rhythm\")\n",
    "            if result['harmonic_similarity'] > 0.7:\n",
    "                strengths.append(\"Natural harmony\")\n",
    "            if result['scale_consistency'] > 0.7:\n",
    "                strengths.append(\"Consistent scale\")\n",
    "            if result['musical_structure'] > 0.6:\n",
    "                strengths.append(\"Good structure\")\n",
    "            \n",
    "            print(\", \".join(strengths) if strengths else \"Needs improvement\")\n",
    "            print()\n",
    "    \n",
    "    def plot_comparison(self, results):\n",
    "        \"\"\"Create visualization comparing the files\"\"\"\n",
    "        if not results:\n",
    "            return\n",
    "        \n",
    "        # Create radar chart\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Bar chart comparison\n",
    "        files = [r['file'] for r in results]\n",
    "        metrics = ['harmonic_similarity', 'rhythmic_consistency', 'scale_consistency', 'musical_structure']\n",
    "        metric_labels = ['Harmonic\\nSimilarity', 'Rhythmic\\nConsistency', \n",
    "                        'Scale\\nConsistency', 'Musical\\nStructure']\n",
    "        \n",
    "        x = np.arange(len(files))\n",
    "        width = 0.2\n",
    "        \n",
    "        for i, metric in enumerate(metrics):\n",
    "            values = [r[metric] for r in results]\n",
    "            ax1.bar(x + i*width, values, width, label=metric_labels[i])\n",
    "        \n",
    "        ax1.set_xlabel('Generated Files')\n",
    "        ax1.set_ylabel('Score (Higher = Better)')\n",
    "        ax1.set_title('Metric Comparison - All Higher = Better')\n",
    "        ax1.set_xticks(x + width * 1.5)\n",
    "        ax1.set_xticklabels(files, rotation=45)\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.set_ylim(0, 1.0)  # Set consistent scale\n",
    "        \n",
    "        # Composite scores\n",
    "        composite_scores = [r['composite_score'] for r in results]\n",
    "        bars = ax2.bar(files, composite_scores, color=['gold', 'silver', 'orange'][:len(files)])\n",
    "        ax2.set_ylabel('Composite Score (Higher = Better)')\n",
    "        ax2.set_title('Overall Ranking')\n",
    "        ax2.set_xticklabels(files, rotation=45)\n",
    "        ax2.set_ylim(0, 1.0)  # Set consistent scale\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, score in zip(bars, composite_scores):\n",
    "            height = bar.get_height()\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{score:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e1614a-436e-4c95-9664-4a8e45fd1ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_generated_music(test_midi_dir, generated_files):\n",
    "    \"\"\"\n",
    "    Main function to evaluate generated MIDI files\n",
    "    \n",
    "    Args:\n",
    "        test_midi_dir: Directory containing reference/test MIDI files\n",
    "        generated_files: List of paths to generated MIDI files to compare\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize evaluator\n",
    "    evaluator = MIDIEvaluator(test_midi_dir)\n",
    "    \n",
    "    # Compare files\n",
    "    results = evaluator.compare_midi_files(generated_files)\n",
    "    \n",
    "    # Plot comparison\n",
    "    evaluator.plot_comparison(results)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d72a9f8f-ee96-47c8-b39a-9c378714b585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 77 test MIDI files for reference\n",
      "Computing test set statistics...\n",
      "Processed 77 valid MIDI files from test set\n",
      "\n",
      "üéµ Evaluating 3 generated MIDI files...\n",
      "\n",
      "üìä very_long_music3.mid:\n",
      "   Harmonic Similarity: 0.7431 (higher = better)\n",
      "   Rhythmic Consistency: 0.6440 (higher = better)\n",
      "   Scale Consistency: 0.5516 (higher = better)\n",
      "   Musical Structure: 0.7916 (higher = better)\n",
      "\n",
      "üìä transformer_music.mid:\n",
      "   Harmonic Similarity: 0.7508 (higher = better)\n",
      "   Rhythmic Consistency: 0.6188 (higher = better)\n",
      "   Scale Consistency: 0.4803 (higher = better)\n",
      "   Musical Structure: 0.6578 (higher = better)\n",
      "\n",
      "üìä pretrained_gen_music.mid:\n",
      "   Harmonic Similarity: 0.5602 (higher = better)\n",
      "   Rhythmic Consistency: 0.5929 (higher = better)\n",
      "   Scale Consistency: 0.5990 (higher = better)\n",
      "   Musical Structure: 0.5612 (higher = better)\n",
      "\n",
      "üèÜ RANKING (Best to Worst):\n",
      "\n",
      "1. very_long_music3.mid\n",
      "   Overall Score: 0.6826\n",
      "   Best aspects: Good rhythm, Natural harmony, Good structure\n",
      "\n",
      "2. transformer_music.mid\n",
      "   Overall Score: 0.6269\n",
      "   Best aspects: Good rhythm, Natural harmony, Good structure\n",
      "\n",
      "3. pretrained_gen_music.mid\n",
      "   Overall Score: 0.5783\n",
      "   Best aspects: Needs improvement\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2558/4216920351.py:467: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax2.set_xticklabels(files, rotation=45)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TEST_MIDI_DIR = \"test_data\"\n",
    "GENERATED_FILES = [\n",
    "    \"very_long_music3.mid\",\n",
    "    \"transformer_music.mid\", \n",
    "    \"pretrained_gen_music.mid\"\n",
    "]\n",
    "results = evaluate_generated_music(TEST_MIDI_DIR, GENERATED_FILES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
